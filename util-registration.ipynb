{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27f22634",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-26T13:04:17.804023Z",
     "iopub.status.busy": "2023-08-26T13:04:17.803586Z",
     "iopub.status.idle": "2023-08-26T13:04:17.811312Z",
     "shell.execute_reply": "2023-08-26T13:04:17.809744Z"
    },
    "papermill": {
     "duration": 0.019395,
     "end_time": "2023-08-26T13:04:17.816145",
     "exception": false,
     "start_time": "2023-08-26T13:04:17.796750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a948101",
   "metadata": {
    "papermill": {
     "duration": 0.003981,
     "end_time": "2023-08-26T13:04:17.824630",
     "exception": false,
     "start_time": "2023-08-26T13:04:17.820649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95b995a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T13:04:17.835489Z",
     "iopub.status.busy": "2023-08-26T13:04:17.835042Z",
     "iopub.status.idle": "2023-08-26T13:04:20.301996Z",
     "shell.execute_reply": "2023-08-26T13:04:20.300551Z"
    },
    "papermill": {
     "duration": 2.476336,
     "end_time": "2023-08-26T13:04:20.305227",
     "exception": false,
     "start_time": "2023-08-26T13:04:17.828891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from math import sqrt, atan2, pi\n",
    "\n",
    "from scipy.interpolate import RectBivariateSpline as rbs\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# from scipy.stats import pearsonr\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7f6b9",
   "metadata": {
    "papermill": {
     "duration": 0.004125,
     "end_time": "2023-08-26T13:04:20.314226",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.310101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "target_for_ncc_optimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8a776c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T13:04:20.325417Z",
     "iopub.status.busy": "2023-08-26T13:04:20.324868Z",
     "iopub.status.idle": "2023-08-26T13:04:20.428583Z",
     "shell.execute_reply": "2023-08-26T13:04:20.427156Z"
    },
    "papermill": {
     "duration": 0.113355,
     "end_time": "2023-08-26T13:04:20.431802",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.318447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_transform(gt, ci_s,F = None, indices = None):    \n",
    "    '''\n",
    "    Perform similarity (shifts+scale+rotation) transform.\n",
    "    \n",
    "    Input:\n",
    "        gt - geometric transformation parameters (center_x, center_y, scale, rot)\n",
    "                [center_x, center_y - coordinates of CI (current image) center\n",
    "                 relative to RI (reference image) grid],\n",
    "                    rot in degrees.;\n",
    "        ci_s - size of CI,\n",
    "               suposed be squred);                  # XXX - Attension.\n",
    "        F - RI-based interpolant;\n",
    "        indices - indices for selected samples (for bootstrap mode,\n",
    "                    in FORTRAN style).\n",
    "    Output:\n",
    "        ri_fragm - evaluated samples in transformed coordinates;\n",
    "        xGrid, yGrid - new X and Y coordinates.\n",
    "        \n",
    "    Comments:\n",
    "        ri_fragm, xGrid, yGrid - 1D arrays (flattened 2D image).\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    center_x = gt[0]\n",
    "    center_y = gt[1]\n",
    "    scale = gt[2]\n",
    "    rot = gt[3]\n",
    "    \n",
    "    \n",
    "    #%% Form the initial not scaled and not rotated grid.\n",
    "    ini_x = center_x - (ci_s-1)/2\n",
    "    ini_y = center_y - (ci_s-1)/2\n",
    "\n",
    "    [Y_,X_] = np.meshgrid(np.arange(ci_s), np.arange(ci_s))          \n",
    "    ci_xShifts = ini_x + X_.flatten(order='F')\n",
    "    ci_yShifts = ini_y + Y_.flatten(order='F')\n",
    "    \n",
    "    if indices is not None:        # Bootstrap mode.\n",
    "        ci_xShifts = ci_xShifts[indices]\n",
    "        ci_yShifts = ci_yShifts[indices]\n",
    "        \n",
    "    # Transformation matrix.\n",
    "        # (we consider the rows as X coordinate, and columns as Y coordinate)\n",
    "    tM = cv2.getRotationMatrix2D( (center_x,center_y), rot,scale)\n",
    "    \n",
    "    src = np.array([ci_xShifts,ci_yShifts]).T\n",
    "    src_ = np.array([src])\n",
    "    dst = cv2.transform(src_, tM)[0]\n",
    "    \n",
    "    xGrid = dst[:,0]\n",
    "    yGrid = dst[:,1]\n",
    "    \n",
    "    if F is None:\n",
    "        ri_fragm = None\n",
    "    else:\n",
    "        ri_fragm = F.ev(xGrid, yGrid)        # XXX - ri_fragm is 1D array.\n",
    "    return ri_fragm, xGrid, yGrid\n",
    "\n",
    "\n",
    "#%%\n",
    "# @numba.jit\n",
    "@numba.jit(nopython=True)\n",
    "def my_pearson(x, y):\n",
    "    '''\n",
    "    My realization of Pearson correlation coefficient.\n",
    "    \n",
    "    Input:\n",
    "        x, y - input 1D numpy arrays of equal length.\n",
    "    Output:\n",
    "        r - Pearson correlation coefficient.\n",
    "        \n",
    "    Comments:\n",
    "        If the calculation results in division by zero, then r = nan (float64).\n",
    "        Function is designed to work effectively with numba JIT.\n",
    "        Don't work when x or y are lists.\n",
    "    '''\n",
    "    \n",
    "    n = x.size\n",
    "    n = y.size   # This added to make sure that x or y are numpy ndarrays.\n",
    "                     # (for example, lists don't have size method).\n",
    "    mean_x = 0.\n",
    "    mean_y = 0.\n",
    "    for k in range(n):\n",
    "        mean_x = mean_x + x[k]\n",
    "        mean_y = mean_y + y[k]\n",
    "    mean_x = mean_x / n\n",
    "    mean_y = mean_y / n\n",
    "    \n",
    "    sum_k = 0.\n",
    "    dx_sum = 0.\n",
    "    dy_sum = 0.\n",
    "    for k in range(n):\n",
    "        sum_k = sum_k + (x[k]-mean_x)*(y[k]-mean_y)\n",
    "        dx_sum = dx_sum + (x[k]-mean_x)**2\n",
    "        dy_sum = dy_sum + (y[k]-mean_y)**2\n",
    "        \n",
    "    denum = np.sqrt(dx_sum*dy_sum) \n",
    "    if denum != 0:\n",
    "        r = sum_k / denum\n",
    "    else:\n",
    "        r = np.nan\n",
    "    return r\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "def target_for_ncc_optimiz(x,ci,F,indices = None):\n",
    "    '''\n",
    "    Target function for ncc (normalized cross correlation) optimization in registration problem.\n",
    "    \n",
    "    Input:\n",
    "        x - current geometric transformation parameters (center_x, center_y, scale, rot)\n",
    "                [center_x, center_y - coordinates of ci center relative to ri grid],\n",
    "                        rot in degrees.;\n",
    "        ci - current image (CI),\n",
    "               suposed be squred);                  # XXX - Attension.\n",
    "        F - RI (reference image) based interpolant (RectBivariateSpline object);\n",
    "        indices - indices for selected samples (for bootstrap mode,\n",
    "                    in FORTRAN style).\n",
    "    Output:\n",
    "        neg_pc - ncc with minus sign.\n",
    "    '''\n",
    "    \n",
    "    ci_s = ci.shape[0]\n",
    "    ri_fragm, _, _ = similarity_transform(x,ci_s,F,indices)\n",
    "\n",
    "\n",
    "    #%%\n",
    "    if indices is not None:\n",
    "        ci = ci.flatten(order='F')\n",
    "        ci = ci[indices]\n",
    "        \n",
    "    # --- Very slow ---\n",
    "    # (pc,_) = pearsonr(ci.flatten(order='F'),\n",
    "    #                   ri_fragm.flatten(order='F'))\n",
    "    \n",
    "    pc = my_pearson(ci.flatten(order='F'),\n",
    "                    ri_fragm.flatten(order='F') )\n",
    "    \n",
    "    neg_pc = -pc\n",
    "    return neg_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093e53a",
   "metadata": {
    "papermill": {
     "duration": 0.004057,
     "end_time": "2023-08-26T13:04:20.440431",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.436374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ncc_optimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94dd6c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T13:04:20.451760Z",
     "iopub.status.busy": "2023-08-26T13:04:20.450496Z",
     "iopub.status.idle": "2023-08-26T13:04:20.459773Z",
     "shell.execute_reply": "2023-08-26T13:04:20.458606Z"
    },
    "papermill": {
     "duration": 0.018068,
     "end_time": "2023-08-26T13:04:20.462653",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.444585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "def ncc_optimiz(ri,ci, x0,\n",
    "                indices = None):\n",
    "    '''\n",
    "    Realize NCC (normalized cross correlation) image registration by optimization.\n",
    "    \n",
    "    Input:\n",
    "        ri - reference image;\n",
    "        ci - current image (CI),\n",
    "             suposed be squred);                  # XXX - Attension.\n",
    "        x0 - initial geometric transformation parameters (center_x, center_y, scale, rot)\n",
    "                [center_x, center_y - coordinates of ci center relative to ri grid],\n",
    "                rot in degrees.;\n",
    "        indices - indices for selected samples (for bootstrap mode,\n",
    "                                                in FORTRAN style).\n",
    "    Output:\n",
    "        res.x - the value of the geometric transformation found as a result \n",
    "                    of optimization.\n",
    "    '''\n",
    "    \n",
    "    # Currently only works 'nelder-mead' method.\n",
    "    method_ = 'nelder-mead'  # 'nelder-mead', 'Powell','CG', \n",
    "                             # 'BFGS', 'Newton-CG', 'dogleg', \n",
    "                             # 'trust-ncg', 'trust-exact’ ', 'trust-krylov'\n",
    "\n",
    "    \n",
    "    #%%\n",
    "    (n,m) = ri.shape\n",
    "    F = rbs(np.arange(n), np.arange(m), ri)\n",
    "    \n",
    "    #%%    \n",
    "    # --- DEBUG (with {'disp':True} ) ---        \n",
    "    # res = minimize(target_for_ncc_optimiz, x0, method=method_,\n",
    "    #               options={'disp': True},\n",
    "    #               args=(ci,F,indices))\n",
    "    # -----------------------\n",
    "    \n",
    "    res = minimize(target_for_ncc_optimiz, x0, method=method_,\n",
    "                   args=(ci,F,indices))\n",
    "\n",
    "    # --- DEBUG---\n",
    "    # print('res.nit = ',res.nit)\n",
    "    # print('res.nfev = ',res.nfev)\n",
    "    # print()\n",
    "    # -----------------------\n",
    "\n",
    "    return res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8aeb6d",
   "metadata": {
    "papermill": {
     "duration": 0.004218,
     "end_time": "2023-08-26T13:04:20.471397",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.467179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "transf_2stage_estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efc2577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-26T13:04:20.483155Z",
     "iopub.status.busy": "2023-08-26T13:04:20.482379Z",
     "iopub.status.idle": "2023-08-26T13:04:20.517686Z",
     "shell.execute_reply": "2023-08-26T13:04:20.516694Z"
    },
    "papermill": {
     "duration": 0.044947,
     "end_time": "2023-08-26T13:04:20.520581",
     "exception": false,
     "start_time": "2023-08-26T13:04:20.475634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XXX - DEBUG\n",
    "debug_flag = False      # True, False\n",
    "\n",
    "\n",
    "#%%    Relative MinMax scaler.\n",
    "def im_scaler(src,low_i,high_i):\n",
    "    '''\n",
    "        [--Don't used at this time--]\n",
    "    Scales an image from [low_i,high_i] to [0,255] bounds.\n",
    "    \n",
    "    Input:\n",
    "        src - source image (array-like) for scaling;\n",
    "        low_i,high_i - defined initial borders.\n",
    "    Output:\n",
    "        dst - destination image.\n",
    "    '''\n",
    "    \n",
    "    min_ = 0\n",
    "    max_ = 255\n",
    "    scale = (max_ - min_) / (high_i - low_i)\n",
    "    dst = scale * (src-low_i)  + min_                                                   \n",
    "    return dst\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def extract__scale_rot(M):\n",
    "    '''\n",
    "    Extract scale and rotation parameters from transformation matrix.\n",
    "    \n",
    "    Input:\n",
    "        M - transformation matrix (from opencv getRotationMatrix2D).\n",
    "    Output:\n",
    "        sc,rot - scaling and rotation parameters,\n",
    "                rot in degrees.\n",
    "        \n",
    "    Comments:\n",
    "        See the documentation for opencv (4) getRotationMatrix2D to understand \n",
    "            proposed formulas.\n",
    "    '''\n",
    "\n",
    "    sc = sqrt(M[0,0]**2 + M[1,0]**2)\n",
    "    rot = atan2(-M[1,0], M[1,1])    \n",
    "    rot = rot/pi*180                                                           \n",
    "    return (sc,rot)\n",
    "\n",
    "\n",
    "#%%\n",
    "def keypoint_estim(ri,ci, kp_type = 'sift',ri_kp_des = None):\n",
    "    \"\"\"\n",
    "    Evaluate similarity transformation parameters by keypoint-based registration.\n",
    "    \n",
    "    Input:\n",
    "        ri - reference image;\n",
    "        ci - current image;\n",
    "        kp_type - detector and descriptor type\n",
    "                    (possible values: 'sift', 'kaze', 'akaze')\n",
    "                    [ri_kp_des if defined should match kp_type];\n",
    "        ri_kp_des - ri keypoints coordinates and descriptors \n",
    "                    (if ri_kp_des defined in input it will not evaluated in function).\n",
    "    Output:\n",
    "        c_end_x, c_end_y, sc, rot - estimated transformation parameters\n",
    "                                    (center_x, center_y, scale, rotation;\n",
    "                                     center_x, center_y - coordinates of ci center retive to ri),\n",
    "                            rot in degrees.\n",
    "        \n",
    "    Comments:\n",
    "        If registration fail return:  (0,0,1,0).\n",
    "        At the moment the function is designed to work with kp_type == 'sift'\n",
    "            (other possibilities don't checked).\n",
    "    \"\"\"\n",
    "\n",
    "    if kp_type == 'sift':\n",
    "        # kp_obj = cv2.xfeatures2d.SIFT_create()\n",
    "        kp_obj = cv2.SIFT_create()\n",
    "    elif kp_type == 'kaze':\n",
    "        kp_obj = cv2.KAZE_create()\n",
    "    elif kp_type == 'akaze':\n",
    "        kp_obj = cv2.AKAZE_create()\n",
    "    else:\n",
    "        raise ValueError('Wrong value for kp_obj')\n",
    "    \n",
    "\n",
    "    if ri_kp_des is None:\n",
    "        # Scale ri to [0,255] range.\n",
    "        ri_scaled = cv2.normalize(ri, None, alpha=0, beta=255, \n",
    "                                  norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        \n",
    "        ri_kp, ri_des = kp_obj.detectAndCompute(ri_scaled, None) \n",
    "    else:\n",
    "        ri_kp, ri_des = ri_kp_des\n",
    "\n",
    "    ci_scaled = cv2.normalize(ci, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)         \n",
    "    ci_kp, ci_des = kp_obj.detectAndCompute(ci_scaled, None)\n",
    "\n",
    "    # --- DEBUG+ ---\n",
    "    # print()\n",
    "    # print('--- ci_kp[ind_].pt ---')\n",
    "    # for ind_ in range(len(ci_kp)):\n",
    "    #     print(ci_kp[ind_].pt)\n",
    "    # print()\n",
    "    # -------------\n",
    "\n",
    "\n",
    "    # XXX - Alternative normalization methhod (normalize ci as ri).      \n",
    "# =============================================================================\n",
    "#     low_i = np.amin(ri)\n",
    "#     high_i = np.amax(ri)\n",
    "#     \n",
    "#     ci = im_scaler(ci,low_i,high_i)\n",
    "#     ci[ci > 255] = 255\n",
    "#     ci[ci < 0] = 0\n",
    "#     ci_scaled = ci.astype(np.uint8)\n",
    "#     ci_kp, ci_des = kp_obj.detectAndCompute(ci_scaled, None)\n",
    "# =============================================================================\n",
    "    \n",
    "    if debug_flag:\n",
    "        print()\n",
    "        print('nRI kp = ', len(ri_kp))\n",
    "        print('nCI kp = ', len(ci_kp))\n",
    "        \n",
    "    if (ri_des is None) or (ci_des is None):\n",
    "        \n",
    "        if debug_flag:\n",
    "            print('Couldn\\'t calculate descriptors for ri or ci')\n",
    "        \n",
    "        return (0,0,1,0)       \n",
    "                                              \n",
    "\n",
    "    #%% \n",
    "    # --- FLANN-based match ---\n",
    "    # FLANN_INDEX_KDTREE = 1\n",
    "    # index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    # search_params = dict(checks = 50)\n",
    "    # flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # matches = flann.knnMatch(ci_des, ri_des, k=2)\n",
    "    \n",
    "    # --- BRUTEFORCE-based match ---\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_BRUTEFORCE)\n",
    "    matches = matcher.knnMatch(ci_des, ri_des, 2)\n",
    "\n",
    "    if debug_flag:\n",
    "        print('Number of matches: ',len(matches))\n",
    "    \n",
    "    \n",
    "    #%% Use Lowe's ratio test.\n",
    "    good = []\n",
    "    coef_ = 0.95            # XXX: 0.95 - for MRRS_2020, 0.9 - for ISDMCI_2020.\n",
    "    try:\n",
    "        for m,n in matches:\n",
    "            if m.distance < coef_ * n.distance:                                       \n",
    "                good.append(m)\n",
    "                \n",
    "    except ValueError:        # Handle if ri_kp has only 1 keypoint.\n",
    "        # --- DEBUG ---\n",
    "        # print()\n",
    "        # print( 'Exception in \"for m,n in matches\" (transf_2stage_estim/keypoint_estim)' )\n",
    "        # print('ri_kp = ', ri_kp)\n",
    "        # print('ci_kp = ', ci_kp)\n",
    "        # print()\n",
    "        # --------------\n",
    "        return (0,0,1,0) \n",
    "\n",
    "    if debug_flag:\n",
    "        print('Len good = ', len(good))\n",
    "    \n",
    "    \n",
    "    #%% Transformation matrix evaluation. \n",
    "    MIN_MATCH_COUNT = 6\n",
    "    if len(good) >= MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ ci_kp[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ ri_kp[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "      \n",
    "        # --- DEBUG+  visualize keyppoints) ---\n",
    "        # print('ci.shape = ', ci.shape)\n",
    "        # nKp = 7      # Number of depicted keypoints.\n",
    "        # src_pts = src_pts[:nKp,:,:]\n",
    "        # print('src_pts = ', src_pts)\n",
    "        # print()\n",
    "        # ci_kp = [ ci_kp[m.queryIdx] for m in good ]   # Sort keypoints.\n",
    "        # ci_kp = ci_kp[:nKp]    \n",
    "\n",
    "        # img_with_kp = cv2.drawKeypoints(ci.astype('uint8'),\n",
    "        #                                 ci_kp, outImage = None)\n",
    "        # cv2.imwrite('im_with_keypoints.jpg',img_with_kp)\n",
    "        # raise NameError('Stop execution to see the keypoints')\n",
    "        # ----------------------------\n",
    "        \n",
    "        \n",
    "        # Find transformation FROM src_pts (CI) points TO dst_pts (RI) points\n",
    "        #    (in CI grid origin is assumed at top-left corner; \n",
    "        #     this differs from our setup, that the origin is in the center of the CI,\n",
    "        #     we take this into account when calculating the transformation parameters ).\n",
    "        M, inlier = cv2.estimateAffinePartial2D(src_pts, dst_pts)      \n",
    "        \n",
    "    else:\n",
    "        if debug_flag:\n",
    "            print(\"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT))\n",
    "            \n",
    "        return (0,0,1,0)     \n",
    "    \n",
    "    \n",
    "    #%%\n",
    "    # Calculate scale, rotation. \n",
    "    if M is not None:\n",
    "        (sc,rot) = extract__scale_rot(M)\n",
    "        # Since cv2.getRotationMatrix2D (with which we model trasformation in make_radPattern_im function) \n",
    "        #     and (cv2.estimateAffinePartial2D which we used to estimate transformation) use\n",
    "        #     different convension (for rotation direction) we should change the sign.\n",
    "        rot = -rot    \n",
    "    else:   \n",
    "        return (0,0,1,0)\n",
    "    \n",
    "    \n",
    "    #%% Estimate CI center position.\n",
    "    (n_ci, m_ci) = ci.shape\n",
    "    c_x_ini = n_ci/2-0.5\n",
    "    c_y_ini = m_ci/2-0.5\n",
    "    \n",
    "    c_ini = np.array([ [c_y_ini],\n",
    "                       [c_x_ini],\n",
    "                       [1] ])\n",
    "    c_end = np.dot(M, c_ini)\n",
    "    c_end_x = c_end[1]\n",
    "    c_end_y = c_end[0]\n",
    "    \n",
    "    # Convert to scalars.\n",
    "    c_end_x = c_end_x[0]\n",
    "    c_end_y = c_end_y[0]\n",
    "   \n",
    "    return (c_end_x, c_end_y, sc, rot)\n",
    "    \n",
    "    \n",
    "    \n",
    "#%%\n",
    "def transf_2stage_estim(ri,ci,\n",
    "                        indices = None,\n",
    "                        ri_kp_des = None,\n",
    "                        true_gt_tuple = None):\n",
    "    '''\n",
    "    Estimate similarity transformation parameters by 2-stage registration.\n",
    "    \n",
    "    Input:\n",
    "        ri - reference image;\n",
    "        ci - current image;\n",
    "        indices - indices for bootstrap (in FORTRAN style);\n",
    "        ri_kp_des - ri keypoints coordinates and descriptors \n",
    "                    (if ri_kp_des defined in input it will not evaluated in function);\n",
    "        true_gt_tuple - true transformation values for speed-up mode (used in this function): \n",
    "                        if 1st registration step estimates bad - we don't evaluate 2nd step\n",
    "                        (in real situation we don't know how bad or not 1st step estimates).\n",
    "    Output:\n",
    "        gt_kp - transformation parameters by 1st stage (tuple);\n",
    "        gt_ncc - transformation parameters by 1st stage (ndarray or tuple).\n",
    "        \n",
    "    Comments:\n",
    "        If indices==None  ->  without bootstrap.\n",
    "    '''\n",
    "    \n",
    "    #%% --- 1 stage ---\n",
    "    # Geometric transformation (gt) estimation by keypoints-based registration.\n",
    "    gt_kp = keypoint_estim(ri,ci,ri_kp_des = ri_kp_des)\n",
    "\n",
    "    \n",
    "    #%% --- 2 stage ---\n",
    "    x0 = gt_kp\n",
    "    if true_gt_tuple is not None:           # For speed-up.\n",
    "        # Bounds on errors for speed-up mode (relative to true values).\n",
    "        sh_b = 4           \n",
    "        sc_b = 0.1          \n",
    "        rot_b = 10          # in degrees.\n",
    "        # Alternative: sh_b = 2, sc_b = 0.05, rot_b = 5 (as in Kybic_bs and functions.statistic.monteCarlo_reg)\n",
    "        \n",
    "        bound4_tuple = (sh_b, sh_b, sc_b, rot_b)\n",
    "        bound4_array = np.array(bound4_tuple)\n",
    "        \n",
    "        true_gt_array = np.array(true_gt_tuple)\n",
    "        gt_kp_array = np.array(gt_kp)\n",
    "        \n",
    "        true_abs_err4 = np.absolute( gt_kp_array - true_gt_array )\n",
    "        if np.all(true_abs_err4 < bound4_array):\n",
    "            gt_ncc = ncc_optimiz(ri,ci, x0,\n",
    "                                 indices)\n",
    "        else:\n",
    "            gt_ncc = (-100,-100,-100,-100)\n",
    "    else:\n",
    "        gt_ncc = ncc_optimiz(ri,ci, x0,\n",
    "                             indices)\n",
    "    \n",
    "    return gt_kp, gt_ncc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.480967,
   "end_time": "2023-08-26T13:04:22.930806",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-26T13:04:04.449839",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
