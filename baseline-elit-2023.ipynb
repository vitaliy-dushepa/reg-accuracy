{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dushepa/baseline-elit-2023?scriptVersionId=143977538\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom scipy.stats import pearsonr\nfrom sklearn.pipeline import Pipeline\n\nfrom matplotlib import pyplot as plt\nimport numpy as np \nimport pandas as pd \n\nimport cv2\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-23T14:31:55.443585Z","iopub.execute_input":"2023-09-23T14:31:55.443966Z","iopub.status.idle":"2023-09-23T14:31:55.450324Z","shell.execute_reply.started":"2023-09-23T14:31:55.443935Z","shell.execute_reply":"2023-09-23T14:31:55.448997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- realWsum,  AVIRIS_d ---  (data_preporation_for_elit_2023)\ntrain_data_path_1 = '/kaggle/input/im-registration-accur-estimation/train__wSum__AVIRIS_d__4980p.csv'\ntrain_1 = pd.read_csv(train_data_path_1)\n\ntest_data_path_1 = '/kaggle/input/im-registration-accur-estimation/test__wSum__AVIRIS_d__879p.csv'\ntest_1 = pd.read_csv(test_data_path_1)\n\n\n\nvalid_data_path_1 = '/kaggle/input/im-registration-accur-estimation/valid__wSum__AVIRIS_d__1996p.csv'\nvalid_1 = pd.read_csv(valid_data_path_1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.452579Z","iopub.execute_input":"2023-09-23T14:31:55.452994Z","iopub.status.idle":"2023-09-23T14:31:55.577655Z","shell.execute_reply.started":"2023-09-23T14:31:55.452959Z","shell.execute_reply":"2023-09-23T14:31:55.576715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_1.copy()\ntest = test_1.copy()\n\nvalid = valid_1.copy()\n\nselect_par = 'P'    # 'x', 'y', 'sc', 'rot', 'P'\n\n# is_P_thresh = True","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.581075Z","iopub.execute_input":"2023-09-23T14:31:55.582048Z","iopub.status.idle":"2023-09-23T14:31:55.588694Z","shell.execute_reply.started":"2023-09-23T14:31:55.582011Z","shell.execute_reply":"2023-09-23T14:31:55.587605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.590161Z","iopub.execute_input":"2023-09-23T14:31:55.59059Z","iopub.status.idle":"2023-09-23T14:31:55.602929Z","shell.execute_reply.started":"2023-09-23T14:31:55.590557Z","shell.execute_reply":"2023-09-23T14:31:55.601545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.605551Z","iopub.execute_input":"2023-09-23T14:31:55.606449Z","iopub.status.idle":"2023-09-23T14:31:55.634596Z","shell.execute_reply.started":"2023-09-23T14:31:55.606415Z","shell.execute_reply":"2023-09-23T14:31:55.633465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train[['rmse_x__ncc', 'rmse_y__ncc', 'rmse_rot__ncc', 'rmse_sc__ncc']]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.635862Z","iopub.execute_input":"2023-09-23T14:31:55.636368Z","iopub.status.idle":"2023-09-23T14:31:55.647867Z","shell.execute_reply.started":"2023-09-23T14:31:55.636334Z","shell.execute_reply":"2023-09-23T14:31:55.647001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\ntest.tail()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.649164Z","iopub.execute_input":"2023-09-23T14:31:55.64959Z","iopub.status.idle":"2023-09-23T14:31:55.677707Z","shell.execute_reply.started":"2023-09-23T14:31:55.649557Z","shell.execute_reply":"2023-09-23T14:31:55.676879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)\n# test[['P__ncc','rmse_x__ncc', 'p_Kybic','Kybic_x']] [200:300]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.680776Z","iopub.execute_input":"2023-09-23T14:31:55.681029Z","iopub.status.idle":"2023-09-23T14:31:55.687316Z","shell.execute_reply.started":"2023-09-23T14:31:55.681006Z","shell.execute_reply":"2023-09-23T14:31:55.686411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- DEBUG (Check for duplicate rows ---                                           # Attention\nduplicate_train_Rows = train[train.duplicated()]\nprint(duplicate_train_Rows)\n\nduplicate_test_Rows = test[test.duplicated()]\nprint(duplicate_test_Rows)\n\n\nduplicate_test_Rows = valid[valid.duplicated()]\nprint(duplicate_test_Rows)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.688984Z","iopub.execute_input":"2023-09-23T14:31:55.689665Z","iopub.status.idle":"2023-09-23T14:31:55.744309Z","shell.execute_reply.started":"2023-09-23T14:31:55.689633Z","shell.execute_reply":"2023-09-23T14:31:55.743389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%\n\nif select_par != 'P':\n    print('len TRAIN before = ', len(train))\n    train.dropna(inplace = True)\n    print('len TRAIN after = ', len(train))\n    print()\n\n    print('len TEST before = ', len(test))\n    test.dropna(inplace = True)\n    print('len TEST after = ', len(test))\n\n\n\n    print('len VALID before = ', len(valid))\n    valid.dropna(inplace = True)\n    print('len VALID after = ', len(valid))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.745651Z","iopub.execute_input":"2023-09-23T14:31:55.746199Z","iopub.status.idle":"2023-09-23T14:31:55.753568Z","shell.execute_reply.started":"2023-09-23T14:31:55.746162Z","shell.execute_reply":"2023-09-23T14:31:55.752478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par != 'P':\n\n    P0 = 0.9                                                                                         # Attention\n\n    # Select rows with P >= P0\n    print('len TRAIN before = ', len(train))\n    indexces = (train['P__ncc'] >= P0)\n    train = train[indexces]\n    print('len TRAIN after = ', len(train))      # 3351\n\n\n\n    # Select rows with P >= P0\n    print('len TEST before = ', len(test))\n    indexces = (test['P__ncc'] >= P0)\n    test = test[indexces]\n    print('len TEST after = ', len(test))        # 634\n\n\n\n    print('len VALID before = ', len(valid))\n    indexces = (valid['P__ncc'] >= P0)\n    valid = valid[indexces]\n    print('len TRAIN after = ', len(valid))      # 1306\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.759049Z","iopub.execute_input":"2023-09-23T14:31:55.759382Z","iopub.status.idle":"2023-09-23T14:31:55.76962Z","shell.execute_reply.started":"2023-09-23T14:31:55.75935Z","shell.execute_reply":"2023-09-23T14:31:55.767834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par != 'P':\n    indexces_train = train.index\n    # indexces_train\n\n    indexces_test = test.index\n    # indexces_test\n\n    indexces_valid = valid.index\n    indexces_valid","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.771667Z","iopub.execute_input":"2023-09-23T14:31:55.77322Z","iopub.status.idle":"2023-09-23T14:31:55.784338Z","shell.execute_reply.started":"2023-09-23T14:31:55.773187Z","shell.execute_reply":"2023-09-23T14:31:55.783421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"code","source":"# --- All variants ---\n# features = ['ci_s'] \n#            ['subpix_x', 'subpix_y'], ---     \n#            ['scale', 'rot']\n#            ['mdx','mdy','widx','widy']\n#             ['quasi_CRLB_x', 'quasi_CRLB_y', 'quasi_CRLB_sc', 'quasi_CRLB_rot']  ---\n#             ['Kybic_x','Kybic_y','Kybic_sc','Kybic_rot']\n#             ['Kybic_x_y','Kybic_x_sc','Kybic_x_rot',\n#              'Kybic_y_sc','Kybic_y_rot','Kybic_sc_rot']\n#     Possible promising features (used in ELNANO):\n#  'dK2_dx', 'dK2_dy',\n#  'r_max','x_of_max','y_of_max','r_sd',\n#  'rr_max','x_of_rrmax','y_of_rrmax','rr_sd',\n#  'cr6', 'H'\n#\n# 'p_Kybic'                                                                   # Attention - new feature\n\nif select_par == 'P':\n    features = ['p_Kybic',\n                'ci_s',\n                'scale', 'rot',\n                'mdx','mdy','widx','widy']\n    \nelse:\n    features = ['Kybic_x','Kybic_y','Kybic_sc','Kybic_rot',\n                'ci_s',\n                'scale', 'rot',\n                'mdx','mdy','widx','widy',\n                'Kybic_x_y','Kybic_x_sc','Kybic_x_rot',\n                'Kybic_y_sc','Kybic_y_rot','Kybic_sc_rot']","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.785792Z","iopub.execute_input":"2023-09-23T14:31:55.78618Z","iopub.status.idle":"2023-09-23T14:31:55.796881Z","shell.execute_reply.started":"2023-09-23T14:31:55.786147Z","shell.execute_reply":"2023-09-23T14:31:55.795994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Create X and y\n\n# To scale very small features values (some ML algorithms may need it).\n# targ_norm_coef = 1000   \ntarg_norm_coef = 1000                                                                           # Attention\n\nadd_norm_for_sc = 10\n\n\n# ----------------------\nif select_par == 'x':\n    y_targ = train.rmse_x__ncc   *  targ_norm_coef\nelif select_par == 'y':\n    y_targ = train.rmse_y__ncc   *  targ_norm_coef\nelif select_par == 'sc':\n    y_targ = train.rmse_sc__ncc  *  targ_norm_coef*add_norm_for_sc\nelif select_par == 'rot':\n    y_targ = train.rmse_rot__ncc  *  targ_norm_coef\nelif select_par == 'P':                                            # Attention\n    y_targ = train.P__ncc\nelse:\n    raise ValueError('Wrong select_par value')\n# ----------------------\n    \nX = train[ features ]\n\n\n'''\n# --- DEBUG\nmask = X.isna().any(axis=1)\nprint(mask)\nrows_with_nan = X[mask]\nprint(rows_with_nan)\n'''\n\n\nif select_par == 'P':  \n    X.dropna(inplace = True)\n    indexces_train = X.index\n    y_targ = y_targ[indexces_train]\n\n\nX = X.reset_index(drop=True)\ny_targ = y_targ.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.798225Z","iopub.execute_input":"2023-09-23T14:31:55.798857Z","iopub.status.idle":"2023-09-23T14:31:55.812622Z","shell.execute_reply.started":"2023-09-23T14:31:55.798824Z","shell.execute_reply":"2023-09-23T14:31:55.811467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.81445Z","iopub.execute_input":"2023-09-23T14:31:55.815173Z","iopub.status.idle":"2023-09-23T14:31:55.832702Z","shell.execute_reply.started":"2023-09-23T14:31:55.815138Z","shell.execute_reply":"2023-09-23T14:31:55.831745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVR","metadata":{}},{"cell_type":"code","source":"#%% ----SVR-----\nfrom sklearn.svm import SVR\n\n# --- BEST ---\nmodel = SVR(gamma = 0.041,\n            C = 10.2,\n            epsilon = 1e-4,\n            tol = 1e-3,\n            shrinking = True,\n            cache_size = 1024,\n            verbose = False)\n\n# --- DEBUG ---\n# model = SVR(gamma = 0.041,\n#             C = 21,\n#             epsilon = 3e-5,\n#             tol = 1e-4,\n#             shrinking = True,\n#             kernel = 'sigmoid')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.834412Z","iopub.execute_input":"2023-09-23T14:31:55.83491Z","iopub.status.idle":"2023-09-23T14:31:55.843223Z","shell.execute_reply.started":"2023-09-23T14:31:55.834878Z","shell.execute_reply":"2023-09-23T14:31:55.842137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variant 1.\n# from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n# Variant 2.\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()  \n    \nmy_pipeline = Pipeline(steps=[('scaler', scaler),\n                              ('model', model)\n                            ])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.844644Z","iopub.execute_input":"2023-09-23T14:31:55.84519Z","iopub.status.idle":"2023-09-23T14:31:55.853019Z","shell.execute_reply.started":"2023-09-23T14:31:55.845151Z","shell.execute_reply":"2023-09-23T14:31:55.852364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# nJobs = 1                           \n\n\n# my_pipeline = RandomForestRegressor(n_estimators = 132,\n#                                     n_jobs=nJobs,\n#                                     random_state=1,\n#                                     max_features = 'sqrt',\n#                                     min_samples_split = 2,\n#                                     min_samples_leaf = 5, \n#                                     max_depth = 15,\n#                                     criterion = 'mse',\n#                                     max_samples = 0.8,\n#                                     bootstrap = True )","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.855622Z","iopub.execute_input":"2023-09-23T14:31:55.856524Z","iopub.status.idle":"2023-09-23T14:31:55.865296Z","shell.execute_reply.started":"2023-09-23T14:31:55.856471Z","shell.execute_reply":"2023-09-23T14:31:55.864594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n# nJobs = 1                          \n\n# my_pipeline = XGBRegressor(learning_rate=0.01,\n#                             n_estimators=440,\n#                             n_jobs=nJobs,\n#                             random_state=1,\n#                             max_depth = 2,\n#                             min_child_weight = 1,\n#                             gamma = 0,\n#                             subsample = 0.8,\n#                             colsample_bytree = 0.8,\n#                             reg_alpha = 0.005,\n#                             reg_lambda = 1.2)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.86648Z","iopub.execute_input":"2023-09-23T14:31:55.867217Z","iopub.status.idle":"2023-09-23T14:31:55.881196Z","shell.execute_reply.started":"2023-09-23T14:31:55.867184Z","shell.execute_reply":"2023-09-23T14:31:55.880192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"# from lightgbm import LGBMRegressor\n# nJobs = 1\n\n\n# my_pipeline = LGBMRegressor(n_jobs=nJobs,\n#                             random_state=1,\n#                             importance_type = 'gain',\n#                             learning_rate = 0.01,\n#                             n_estimators = 345,\n#                             boosting_type= 'gbdt',\n#                             num_leaves= 16,\n#                             max_depth = 6,\n#                             objective = None,\n#                             min_child_weight = 1e-3,\n#                             min_child_samples= 17,\n#                             subsample = 0.6,\n#                             subsample_freq = 1,\n#                             colsample_bytree = 0.8,\n#                             reg_alpha = 23.5,\n#                             reg_lambda = 1.35,\n#                             max_bin = 400)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.882568Z","iopub.execute_input":"2023-09-23T14:31:55.883131Z","iopub.status.idle":"2023-09-23T14:31:55.891776Z","shell.execute_reply.started":"2023-09-23T14:31:55.883098Z","shell.execute_reply":"2023-09-23T14:31:55.890825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train fit","metadata":{}},{"cell_type":"code","source":"#%%\nmy_pipeline.fit(X, y_targ)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:55.893261Z","iopub.execute_input":"2023-09-23T14:31:55.894039Z","iopub.status.idle":"2023-09-23T14:31:57.338482Z","shell.execute_reply.started":"2023-09-23T14:31:55.894Z","shell.execute_reply":"2023-09-23T14:31:57.337391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and valid preparation","metadata":{}},{"cell_type":"code","source":"if select_par == 'x':\n    test_y_targ = test.rmse_x__ncc\n    crlb_ = test.CRLB_x         # Yetic_Nehorai estimate.\n    kybic = test.Kybic_x        # Kybic estimate.\n    \n    valid_y_targ = valid.rmse_x__ncc\nelif select_par == 'y':\n    test_y_targ = test.rmse_y__ncc\n    crlb_ = test.CRLB_y\n    kybic = test.Kybic_y \n    \n    valid_y_targ = valid.rmse_y__ncc\nelif select_par == 'sc':\n    test_y_targ = test.rmse_sc__ncc\n    crlb_ = test.CRLB_sc                                          \n    kybic = test.Kybic_sc\n    \n    valid_y_targ = valid.rmse_sc__ncc\nelif select_par == 'rot':\n    test_y_targ = test.rmse_rot__ncc\n    crlb_ = test.CRLB_rot                                          \n    kybic = test.Kybic_rot\n    \n    valid_y_targ = valid.rmse_rot__ncc\n    \nelif select_par == 'P':\n    test_y_targ = test.P__ncc\n    crlb_ = test.p_Kybic         # not make sense, just to make the code work                                     \n    kybic = test.p_Kybic\n    \n    valid_y_targ = valid.P__ncc\nelse:\n    raise ValueError('Wrong select_par value')\n\ntest_X = test[ features ]\nvalid_X = valid[ features ]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:57.340253Z","iopub.execute_input":"2023-09-23T14:31:57.340648Z","iopub.status.idle":"2023-09-23T14:31:57.352679Z","shell.execute_reply.started":"2023-09-23T14:31:57.340614Z","shell.execute_reply":"2023-09-23T14:31:57.351719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par == 'P':  \n    test_X.dropna(inplace = True)\n    indexces_test = test_X.index\n    test_y_targ = test_y_targ[indexces_test]\n\n    valid_X.dropna(inplace = True)\n    indexces_valid = valid_X.index\n    valid_y_targ = valid_y_targ[indexces_valid]\n\n\ntest_X = test_X.reset_index(drop=True)\ntest_y_targ = test_y_targ.reset_index(drop=True)\n\nvalid_X = valid_X.reset_index(drop=True)\nvalid_y_targ = valid_y_targ.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:57.354739Z","iopub.execute_input":"2023-09-23T14:31:57.355087Z","iopub.status.idle":"2023-09-23T14:31:57.367484Z","shell.execute_reply.started":"2023-09-23T14:31:57.355055Z","shell.execute_reply":"2023-09-23T14:31:57.366483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance on train set","metadata":{}},{"cell_type":"code","source":"preds = my_pipeline.predict(X)\nif select_par == 'sc':\n    preds = preds / (targ_norm_coef*add_norm_for_sc)\n    y_targ = y_targ / (targ_norm_coef*add_norm_for_sc)\nelif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n    preds = preds / targ_norm_coef \n    y_targ = y_targ / targ_norm_coef\n\n\nprint()\nprint('My model    (---train performance---)')\n(pc,_) = pearsonr(preds, y_targ.values)\nprint(\"    Pearson correlation :  {0:0.3f} \".format(pc))\n\nr2 = r2_score(y_targ.values,preds)\nprint(\"    r2_score :  {0:0.3f} \".format(r2) )\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:57.368771Z","iopub.execute_input":"2023-09-23T14:31:57.369902Z","iopub.status.idle":"2023-09-23T14:31:58.399671Z","shell.execute_reply.started":"2023-09-23T14:31:57.369868Z","shell.execute_reply":"2023-09-23T14:31:58.39872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance on TEST set","metadata":{}},{"cell_type":"code","source":"test_preds = my_pipeline.predict(test_X)\nif select_par == 'sc':\n    test_preds = test_preds / (targ_norm_coef*add_norm_for_sc)  \nelif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n    test_preds = test_preds / targ_norm_coef\n\n\nprint()\nprint('Yetic_Nehorai')\n(pc,_) = pearsonr(crlb_.values, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values, crlb_.values)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n\n\nprint()\nprint('Kybic')\n(pc,_) = pearsonr(kybic.values, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values,kybic.values)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n\n\nprint()\nprint('My model')\n(pc,_) = pearsonr(test_preds, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values,test_preds)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.401548Z","iopub.execute_input":"2023-09-23T14:31:58.402209Z","iopub.status.idle":"2023-09-23T14:31:58.594869Z","shell.execute_reply.started":"2023-09-23T14:31:58.402173Z","shell.execute_reply":"2023-09-23T14:31:58.593822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# --- Variant 1 (draw only part of points)---\nnFirst = 75\n# plt.figure(figsize = (7,3.8))\nfig = plt.figure(figsize = (5,2.5))\nax = fig.add_subplot(111)\nax.plot(test_y_targ.values[:nFirst],'r', label='true',\n          linewidth=2)\n# plt.plot(crlb_.values[:nFirst],'b', label='CRLB_')\n# plt.plot(kybic.values[:nFirst],'b', label='Kybic')\nax.plot(test_preds[:nFirst],'b--', label='prediction',\n          linewidth=3)\n# ---------------\n\n\n# --- Variant 2 ---\n# plt.plot(test_y_targ.values,'r', label='true')\n# # plt.plot(crlb_.values,'m', label='CRLB_')\n# plt.plot(kybic.values,'k', label='Kybic')\n# plt.plot(test_preds,'b', label='newML')\n# ---------------\n\nplt.grid()\nplt.legend(fontsize=10)\nplt.xlabel('Number of image pair',size =10)\nif select_par == 'x':\n    plt.ylabel('RMSE for X axis',size =10)\nelif select_par == 'y':\n    plt.ylabel('RMSE for Y axis',size =10)\nelif select_par == 'sc':\n    plt.ylabel('RMSE for scale coef',size =10)\nelif select_par == 'rot':\n    plt.ylabel('RMSE for rotation coef',size =10)\nelif select_par == 'P':\n    plt.ylabel('P',size =10)\nelse:\n    raise ValueError('Wrong select_par value')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.596279Z","iopub.execute_input":"2023-09-23T14:31:58.597197Z","iopub.status.idle":"2023-09-23T14:31:58.909271Z","shell.execute_reply.started":"2023-09-23T14:31:58.597162Z","shell.execute_reply":"2023-09-23T14:31:58.908371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- Plots for train predictions (DEBUG) ---\n# plt.figure()\n# plt.title('Performance on the train set')\n# plt.plot(y_targ.values,'r', label='true')\n# plt.plot(preds,'b', label='newML')\n# plt.legend(fontsize=10)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.910866Z","iopub.execute_input":"2023-09-23T14:31:58.911532Z","iopub.status.idle":"2023-09-23T14:31:58.915769Z","shell.execute_reply.started":"2023-09-23T14:31:58.91148Z","shell.execute_reply":"2023-09-23T14:31:58.914808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Neaural network**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\n# import torchvision.transforms.v2 as T2\nimport torchvision.transforms as T\n\nimport random ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.917268Z","iopub.execute_input":"2023-09-23T14:31:58.917908Z","iopub.status.idle":"2023-09-23T14:31:58.929507Z","shell.execute_reply.started":"2023-09-23T14:31:58.917871Z","shell.execute_reply":"2023-09-23T14:31:58.928507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - - - Fixing randomness\n\nrandom.seed(13) \nnp.random.seed(13)\ntorch.manual_seed(13)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.937833Z","iopub.execute_input":"2023-09-23T14:31:58.938104Z","iopub.status.idle":"2023-09-23T14:31:58.947229Z","shell.execute_reply.started":"2023-09-23T14:31:58.938079Z","shell.execute_reply":"2023-09-23T14:31:58.94628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.948854Z","iopub.execute_input":"2023-09-23T14:31:58.949184Z","iopub.status.idle":"2023-09-23T14:31:58.958088Z","shell.execute_reply.started":"2023-09-23T14:31:58.949151Z","shell.execute_reply":"2023-09-23T14:31:58.957145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import image data","metadata":{}},{"cell_type":"code","source":"import pickle\n\nfile = open('/kaggle/input/im-registration-accur-estimation/train__ci_ri_list__4980p.pkl', 'rb')\ntrain__ci_ri_list = pickle.load(file)\nfile.close()\n\nfile = open('/kaggle/input/im-registration-accur-estimation/test__ci_ri_list__879p.pkl', 'rb')\ntest__ci_ri_list = pickle.load(file)\nfile.close()\n\n\n\nfile = open('/kaggle/input/im-registration-accur-estimation/valid__ci_ri_list__1996p.pkl', 'rb')\nvalid__ci_ri_list = pickle.load(file)\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:58.959589Z","iopub.execute_input":"2023-09-23T14:31:58.95993Z","iopub.status.idle":"2023-09-23T14:31:59.29651Z","shell.execute_reply.started":"2023-09-23T14:31:58.959898Z","shell.execute_reply":"2023-09-23T14:31:59.295542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if \"ci_ri_list\" contain None - fixed in last version of data_praparation file\ntrain__ci_ri_list = [el for el in train__ci_ri_list if el is not None]\ntest__ci_ri_list = [el for el in test__ci_ri_list if el is not None]\n\nvalid__ci_ri_list = [el for el in valid__ci_ri_list if el is not None]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.298126Z","iopub.execute_input":"2023-09-23T14:31:59.298466Z","iopub.status.idle":"2023-09-23T14:31:59.304636Z","shell.execute_reply.started":"2023-09-23T14:31:59.298432Z","shell.execute_reply":"2023-09-23T14:31:59.303464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train__ci_ri_list))\nprint(len(test__ci_ri_list))\nprint(len(valid__ci_ri_list))\nprint()\n# print(train__ci_ri_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.306363Z","iopub.execute_input":"2023-09-23T14:31:59.307093Z","iopub.status.idle":"2023-09-23T14:31:59.317974Z","shell.execute_reply.started":"2023-09-23T14:31:59.307059Z","shell.execute_reply":"2023-09-23T14:31:59.316969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(indexces_train[:20])\nprint(indexces_test[:20])\n\nprint(indexces_valid[:20])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.319852Z","iopub.execute_input":"2023-09-23T14:31:59.320243Z","iopub.status.idle":"2023-09-23T14:31:59.330401Z","shell.execute_reply.started":"2023-09-23T14:31:59.32021Z","shell.execute_reply":"2023-09-23T14:31:59.329543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train__ci_ri_list = [train__ci_ri_list[i] for i in indexces_train]\ntest__ci_ri_list = [test__ci_ri_list[i] for i in indexces_test]\n\nvalid__ci_ri_list = [valid__ci_ri_list[i] for i in indexces_valid]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.331459Z","iopub.execute_input":"2023-09-23T14:31:59.33234Z","iopub.status.idle":"2023-09-23T14:31:59.342652Z","shell.execute_reply.started":"2023-09-23T14:31:59.332307Z","shell.execute_reply":"2023-09-23T14:31:59.341684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that length coinside\nprint(len(train__ci_ri_list))\nprint(len(test__ci_ri_list))\nprint(len(valid__ci_ri_list))\nprint()\n\nprint(len(X))\nprint(len(test_X))\nprint(len(valid_X))\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.344157Z","iopub.execute_input":"2023-09-23T14:31:59.344542Z","iopub.status.idle":"2023-09-23T14:31:59.356015Z","shell.execute_reply.started":"2023-09-23T14:31:59.344509Z","shell.execute_reply":"2023-09-23T14:31:59.35492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train__ci_ri_list[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.357175Z","iopub.execute_input":"2023-09-23T14:31:59.357413Z","iopub.status.idle":"2023-09-23T14:31:59.370287Z","shell.execute_reply.started":"2023-09-23T14:31:59.357391Z","shell.execute_reply":"2023-09-23T14:31:59.369319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"\naug_train = T.Compose([ToTensor(),\n                      T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                     interpolation=T.InterpolationMode.BILINEAR)]\n                  )\nno_aug_test = ToTensor()\n'''\nprint()\n'''","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.371343Z","iopub.execute_input":"2023-09-23T14:31:59.371637Z","iopub.status.idle":"2023-09-23T14:31:59.383409Z","shell.execute_reply.started":"2023-09-23T14:31:59.371605Z","shell.execute_reply":"2023-09-23T14:31:59.382507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_size = 60   # 60, 128  , 120                                       # Attention\n\nclass Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    dataset = Dataset(X, y, ci_ri_list)\n    ci_ri_list - list of Hx2H images\n    len(X)==len(ci_ri_list)\n    \n    \n    img, feat, y = dataset[i]\n      img :     image (2xHxH)\n      features : array og features\n      y :    regression target (RMSE_x, RMSE_y, RMSE_scale, RMSE_rot, P, ...)\n          (for 'test data' you can give random y array)\n    \"\"\"\n    \n    def __init__(self, X, y, ci_ri_list, mode=None):\n        self.X = X\n        self.y = y\n        self.ci_ri_list = ci_ri_list\n        self.mode = mode                    # 'train' or None\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, i):\n        ci_ri = self.ci_ri_list[i]\n        n,m = ci_ri.shape\n        # print('n,m = ', n,m),  # m=2*n\n        \n        ci = ci_ri[:, :n]\n        ri_fragm = ci_ri[:, n:]\n        \n        \n        dim = (im_size, im_size)\n        ci_ = cv2.resize(ci, dim, interpolation = cv2.INTER_CUBIC)\n        ri_fragm_ = cv2.resize(ri_fragm, dim, interpolation = cv2.INTER_CUBIC)\n        \n        \n        img = np.zeros( (im_size,im_size,2) )   # H,W, C\n        img[:,:,0] = ci_\n        img[:,:,1] = ri_fragm_\n        \n        img = img/255.0\n        \n        if self.mode == 'train':   # transformation\n            img = aug_train(img)   # C,H,W\n        else:\n            img = no_aug_test(img)\n        \n        # features = self.X.iloc[i,:]\n        features = self.X.iloc[i,:].values\n        \n        y = self.y.iloc[i]\n        # y = np.float64(self.y.iloc[i])\n        \n        return img.float(), torch.tensor(features).float(), torch.tensor(y).float() ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.384622Z","iopub.execute_input":"2023-09-23T14:31:59.385165Z","iopub.status.idle":"2023-09-23T14:31:59.399387Z","shell.execute_reply.started":"2023-09-23T14:31:59.385079Z","shell.execute_reply":"2023-09-23T14:31:59.398349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------------\nif select_par == 'x':\n    y_targ = y_targ   *  targ_norm_coef\nelif select_par == 'y':\n    y_targ = y_targ   *  targ_norm_coef\nelif select_par == 'sc':\n    y_targ = y_targ  *  targ_norm_coef*add_norm_for_sc\nelif select_par == 'rot':\n    y_targ = y_targ  *  targ_norm_coef\nelif select_par == 'P':\n    y_targ = y_targ\nelse:\n    raise ValueError('Wrong select_par value')\n# ----------------------\n\n\nprint('y_targ = ', y_targ[:10])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.401143Z","iopub.execute_input":"2023-09-23T14:31:59.401899Z","iopub.status.idle":"2023-09-23T14:31:59.414572Z","shell.execute_reply.started":"2023-09-23T14:31:59.401867Z","shell.execute_reply":"2023-09-23T14:31:59.413138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(X, y_targ, train__ci_ri_list, mode='train')           # Perform augmentations on samples\n# train_dataset = Dataset(X, y_targ, train__ci_ri_list, mode=None)           # Perform augmentations on batches (modified model)\n\ntest_dataset = Dataset(test_X, test_y_targ, test__ci_ri_list, mode=None)\n\nvalid_dataset = Dataset(valid_X, valid_y_targ, valid__ci_ri_list, mode=None)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.415785Z","iopub.execute_input":"2023-09-23T14:31:59.416742Z","iopub.status.idle":"2023-09-23T14:31:59.429345Z","shell.execute_reply.started":"2023-09-23T14:31:59.416709Z","shell.execute_reply":"2023-09-23T14:31:59.428419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- Examine dataset class\nind = 5\n'''\nimg, feat, y = train_dataset[ind]\n\nprint('img = ', img)\nprint('feat = ', feat)\nprint('y = ', y)\n'''\nimg, feat, y = test_dataset[ind]\n\nprint('img = ', img)\nprint('feat = ', feat)\nprint('y = ', y)\n\nplt.figure()\nplt.imshow(img[0,:,:])\nplt.figure()\nplt.imshow(img[1,:,:])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.430564Z","iopub.execute_input":"2023-09-23T14:31:59.43096Z","iopub.status.idle":"2023-09-23T14:31:59.995932Z","shell.execute_reply.started":"2023-09-23T14:31:59.430926Z","shell.execute_reply":"2023-09-23T14:31:59.994968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"# the code from the example is partially used\n# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n\nbatch_size = 64            # 64  , 128,  256   ,  512  , 1024                                                         # Attention\nvalid_bs = 2*4096\n\n# Create data loaders.\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n                              drop_last=True, shuffle=True,\n                              num_workers=2)                                   # Attention\n\n\ntest_dataloader = DataLoader(test_dataset, batch_size=valid_bs,\n                             drop_last=False, shuffle=False,\n                             num_workers=2)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=valid_bs,\n                             drop_last=False, shuffle=False,\n                             num_workers=2)\n\n# --- DEBUG\nfor img, feat, y in train_dataloader:\n    print(f\"Shape of img [N, C, H, W]: {img.shape}\")\n    print(f\"Shape of feat [N, C, H, W]: {feat.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:31:59.99995Z","iopub.execute_input":"2023-09-23T14:32:00.000781Z","iopub.status.idle":"2023-09-23T14:32:00.624901Z","shell.execute_reply.started":"2023-09-23T14:32:00.000737Z","shell.execute_reply":"2023-09-23T14:32:00.62105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_no_aug = Dataset(X, y_targ, train__ci_ri_list, mode=None)  \ntrain_dataloader_no_aug = DataLoader(train_dataset_no_aug, batch_size=valid_bs,\n                              drop_last=False, shuffle=False,\n                              num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.630908Z","iopub.execute_input":"2023-09-23T14:32:00.634211Z","iopub.status.idle":"2023-09-23T14:32:00.65385Z","shell.execute_reply.started":"2023-09-23T14:32:00.634163Z","shell.execute_reply":"2023-09-23T14:32:00.652897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"mode = 'cnn_with_features'   #  'cnn_with_features', 'cnn_10' ,     'cnn_32' don't used in paper \nattention_mode = True    # only for 'cnn_with_features', 'cnn_10'\nnormFeat_mode = True     # only for 'cnn_with_features' (norm before concat conv[or attention] and hand-made features), \n                         #          'cnn_10'  (norm before concat attention in and out,        work when attention_mode = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.658454Z","iopub.execute_input":"2023-09-23T14:32:00.661091Z","iopub.status.idle":"2023-09-23T14:32:00.671268Z","shell.execute_reply.started":"2023-09-23T14:32:00.661056Z","shell.execute_reply":"2023-09-23T14:32:00.670176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN_3","metadata":{}},{"cell_type":"code","source":"\nif mode == 'cnn_10': \n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            self.conv_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n                \n\n                nn.Conv2d(in_channels=4, out_channels=6, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n                \n\n                nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n\n                \n                nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(10, affine=True),\n                nn.ReLU()\n            )\n\n            \n            n_conv_feat = 10*2*2     # 10*2*2, 810 , 20*2*2                                # Attention\n            # self.norm_on_batch = nn.BatchNorm1d(num_features=n_conv_feat)\n            self.norm_on_batch = nn.BatchNorm1d(num_features=int(n_conv_feat/2))    # if concat with attention case \n            \n            self.norm_on_channel = nn.LayerNorm(normalized_shape=10)  # only on channels \n            \n            self.dense_stack = nn.Sequential(\n                nn.Linear(n_conv_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n            \n            num_heads = 5\n            embed_dim = 10\n            self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n            \n\n        def forward(self, x):\n\n            '''\n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                x = self.transf(x)\n            '''\n            \n            \n            conv_feat = self.conv_stack(x)      # N C H W   (N-batch,  C- channels, H-height, W-width)\n            \n            \n            \n            # - - - - - - With attention\n            if attention_mode:\n                # print('conv_feat.shape = ', conv_feat.shape)\n                conv_feat = conv_feat.flatten(2, 3)     # N C S   (S-sequence)\n                \n                conv_feat_ = conv_feat.permute(2,0,1)    # S N C\n                # --- 1st self-attention \n                attn_output, attn_output_weights = self.multihead_attn(query=conv_feat_, \n                                                                       key=conv_feat_, \n                                                                       value=conv_feat_)     # attn_output    # S N C\n                '''\n                attn_output, attn_output_weights = self.multihead_attn(query=attn_output, \n                                                                       key=attn_output, \n                                                                       value=attn_output)     # attn_output    # S N C\n                '''\n                \n                attn_output_ = attn_output.permute(1,2,0)    # N C S\n                \n                \n                # - - - - - - Norm before concat (in and out of attention)\n                if normFeat_mode:\n                    # --  Norm on batch\n                    '''\n                    conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n                    conv_feat = self.norm_on_batch(conv_feat)\n                    attn_output_ = attn_output_.flatten(1, -1)     # N F    (F-features)\n                    attn_output_ = self.norm_on_batch(attn_output_)\n                    '''\n                    # --  Norm on channel (only attention out)\n                    attn_output_ = attn_output_.permute(0,2,1)    # N S C\n                    attn_output_ = self.norm_on_channel(attn_output_)   # Norm on C (last dimension) only\n                    attn_output_ = attn_output_.permute(0,2,1)    # N C S\n                # - - - - - - - -- - - - - - - -- - - - - -- - \n                \n                \n                \n                # conv_feat = attn_output_                  # only attn_output\n                # conv_feat = conv_feat + attn_output_        # add attn_output with input      # N C S\n                conv_feat = torch.cat((conv_feat, attn_output_), dim=1)         #       # N 2*C S\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            \n            conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n            \n            \n            logits = self.dense_stack(conv_feat)\n            return logits","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.676158Z","iopub.execute_input":"2023-09-23T14:32:00.676708Z","iopub.status.idle":"2023-09-23T14:32:00.706826Z","shell.execute_reply.started":"2023-09-23T14:32:00.676673Z","shell.execute_reply":"2023-09-23T14:32:00.705937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if mode == 'cnn_32': \n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            n_conv_feat = 2592     # 32*2*2,  2592\n            self.cnn_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=8, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n                \n\n                nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(16, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(16, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n                \n\n                nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(24, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(24, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n\n                \n                nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(32, affine=True),\n                nn.ReLU(),\n\n                \n                nn.Flatten(),\n                nn.Linear(n_conv_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n\n        def forward(self, x):\n\n            '''\n            \n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                x = self.transf(x)\n            '''\n            \n            \n            \n            logits = self.cnn_stack(x)\n            return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.711242Z","iopub.execute_input":"2023-09-23T14:32:00.711861Z","iopub.status.idle":"2023-09-23T14:32:00.73188Z","shell.execute_reply.started":"2023-09-23T14:32:00.711828Z","shell.execute_reply":"2023-09-23T14:32:00.731044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine cnn+features","metadata":{}},{"cell_type":"code","source":"# train_metric[-1] =  0.3254600726401089\n# test_metric[-1] =  0.25901960194265294   'rot'\n\nn_feat = len(features)   # 17, 8\n\nif mode == 'cnn_with_features':  \n    print(\"       'cnn_with_features' is used\")\n\n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            self.conv_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n\n                nn.Conv2d(in_channels=4, out_channels=6, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n\n                nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n                \n                nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(10, affine=True),\n                nn.ReLU()\n            )\n            \n            # self.flat = nn.Flatten()\n            \n            n_conv_feat = 10*2*2     # 10*2*2,  20*2*2\n            self.norm_on_batch = nn.BatchNorm1d(num_features=n_conv_feat)\n            # self.norm_on_batch = nn.BatchNorm1d(num_features=int(n_conv_feat/2))    # if concat with attention case\n            \n            self.norm_on_channel = nn.LayerNorm(normalized_shape=10)  # only on channels \n            \n            \n            \n            self.feat_norm = nn.BatchNorm1d(n_feat)\n            \n            self.dense_stack = nn.Sequential(\n                nn.Linear(n_conv_feat + n_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n            \n            num_heads = 5\n            embed_dim = 10\n            self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n            \n\n\n        def forward(self, img, feat):\n            '''\n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                img = self.transf(img)\n                # plt.figure()\n                # plt.imshow(x[0,0,:,:].detach().cpu().numpy())\n            '''\n\n            conv_feat = self.conv_stack(img)    # N C H W   (N-batch,  C- channels, H-height, W-width)\n            \n            # - - - - - - With attention\n            if attention_mode:\n                conv_feat = conv_feat.flatten(2, 3)     # N C S   (S-sequence)\n                conv_feat_ = conv_feat.permute(2,0,1)    # S N C\n                # --- 1st self-attention \n                attn_output, attn_output_weights = self.multihead_attn(query=conv_feat_, \n                                                                       key=conv_feat_, \n                                                                       value=conv_feat_)     # attn_output    # S N C\n                '''\n                attn_output, attn_output_weights = self.multihead_attn(query=attn_output, \n                                                                       key=attn_output, \n                                                                       value=attn_output)     # attn_output    # S N C\n                '''\n                attn_output_ = attn_output.permute(1,2,0)    # N C S\n\n                # - - - - - - Norm out of attention\n                if normFeat_mode:\n                    # - - --  Norm on batch\n                    '''\n                    # conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n                    # conv_feat = self.norm_on_batch(conv_feat)\n                    attn_output_ = attn_output_.flatten(1, -1)     # N F    (F-features)\n                    attn_output_ = self.norm_on_batch(attn_output_)\n                    '''\n                    # --  Norm on channel (only attention out)\n                    attn_output_ = attn_output_.permute(0,2,1)    # N S C\n                    attn_output_ = self.norm_on_channel(attn_output_)   # Norm on C (last dimension) only\n                    attn_output_ = attn_output_.permute(0,2,1)    # N C S\n                    \n                # - - - - - - - -- - - - - - - -- - - - - -- - \n                \n                \n                \n                conv_feat = attn_output_                  # only attn_output\n                # conv_feat = conv_feat + attn_output_        # add attn_output with input      # N C S\n                # conv_feat = torch.cat((conv_feat, attn_output_), dim=1)         #       # N 2*C S\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            \n            conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n            \n            \n            # - - - - - - With feat norm\n            if normFeat_mode:\n                if not attention_mode:\n                    conv_feat = self.norm_on_batch(conv_feat)        # norm by batch\n\n                feat = self.feat_norm(feat)         # N F    (F-features)\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            x = torch.cat((conv_feat,feat), axis=1)    \n\n            logits = self.dense_stack(x)\n            return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.736849Z","iopub.execute_input":"2023-09-23T14:32:00.739559Z","iopub.status.idle":"2023-09-23T14:32:00.772157Z","shell.execute_reply.started":"2023-09-23T14:32:00.739525Z","shell.execute_reply":"2023-09-23T14:32:00.771291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = cnn().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.776869Z","iopub.execute_input":"2023-09-23T14:32:00.777654Z","iopub.status.idle":"2023-09-23T14:32:00.795351Z","shell.execute_reply.started":"2023-09-23T14:32:00.777621Z","shell.execute_reply":"2023-09-23T14:32:00.794575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\nif (mode == 'cnn_10') or (mode == 'cnn_32'): \n    print(\n        summary(model, input_size=(batch_size, 2, im_size, im_size))\n    )\nelif mode == 'cnn_with_features': \n    print(\n        summary(model, input_size=[(batch_size, 2, im_size, im_size), (batch_size,n_feat)] \n                )\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.799085Z","iopub.execute_input":"2023-09-23T14:32:00.799648Z","iopub.status.idle":"2023-09-23T14:32:00.83742Z","shell.execute_reply.started":"2023-09-23T14:32:00.799615Z","shell.execute_reply":"2023-09-23T14:32:00.83662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)         # Attention\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n\nepochs = 250   # 500,  250  , 100                                     # Attention\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=7e-4, steps_per_epoch=len(train_dataloader), epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.841147Z","iopub.execute_input":"2023-09-23T14:32:00.845793Z","iopub.status.idle":"2023-09-23T14:32:00.855084Z","shell.execute_reply.started":"2023-09-23T14:32:00.845751Z","shell.execute_reply":"2023-09-23T14:32:00.854041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.to(torch.double)\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.859128Z","iopub.execute_input":"2023-09-23T14:32:00.861409Z","iopub.status.idle":"2023-09-23T14:32:00.869304Z","shell.execute_reply.started":"2023-09-23T14:32:00.861376Z","shell.execute_reply":"2023-09-23T14:32:00.86853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# the code from the example is partially used\n# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (img, feat, y) in enumerate(dataloader):\n        img, feat, y = img.to(device), feat.to(device), y.to(device)\n\n        # Compute prediction error\n        if mode == 'cnn_with_features':\n            pred = model(img, feat)\n        elif (mode == 'cnn_10') or (mode == 'cnn_32'):\n            pred = model(img)\n        pred = torch.squeeze(pred)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.87082Z","iopub.execute_input":"2023-09-23T14:32:00.872318Z","iopub.status.idle":"2023-09-23T14:32:00.888347Z","shell.execute_reply.started":"2023-09-23T14:32:00.872285Z","shell.execute_reply":"2023-09-23T14:32:00.887519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchmetrics.functional import r2_score as r2_torch     # strangely works for small values\n\ndef evaluate(dataloader, model, mode_='test', \n             metric_='R2'):                           # 'R2', 'Pearson'\n    model.eval()\n    preds = torch.empty((0,), dtype=torch.float64).to(device)\n    ys = torch.empty((0,), dtype=torch.float64).to(device)\n    \n    with torch.no_grad():\n        for img, feat, y in dataloader:\n            img, feat, y = img.to(device), feat.to(device), y.to(device)\n            \n            if mode == 'cnn_with_features':\n                pred = model(img, feat)\n            elif (mode == 'cnn_10') or (mode == 'cnn_32'):\n                pred = model(img)\n                \n            pred = torch.squeeze(pred)\n            preds = torch.cat((preds, pred))\n            ys = torch.cat((ys, y))\n    \n    preds = preds.detach().cpu().numpy()\n    ys = ys.detach().cpu().numpy()\n    \n    # - - - - - - - - - - -\n    if select_par == 'sc':\n        preds = preds / (targ_norm_coef*add_norm_for_sc)\n        if mode_ == 'train':     # for train, target multiplied by constant (small value issue)\n            ys = ys / (targ_norm_coef*add_norm_for_sc)\n    elif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n        preds = preds / targ_norm_coef\n        if mode_ == 'train':\n            ys = ys / targ_norm_coef\n    # - - - - - - - - - - -\n    \n    if metric_ == 'R2':\n        metric = r2_score(ys,preds)      # in sklean function: r2_score(true, pred)\n    elif metric_ == 'Pearson':\n        metric,_ = pearsonr(preds,ys)      # in scipy.stats function: r2_score(pred, true)\n\n    return metric, preds, ys\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.890551Z","iopub.execute_input":"2023-09-23T14:32:00.892479Z","iopub.status.idle":"2023-09-23T14:32:00.910313Z","shell.execute_reply.started":"2023-09-23T14:32:00.892444Z","shell.execute_reply":"2023-09-23T14:32:00.909475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T14:32:00.91454Z","iopub.execute_input":"2023-09-23T14:32:00.916891Z","iopub.status.idle":"2023-09-23T14:32:01.498337Z","shell.execute_reply.started":"2023-09-23T14:32:00.916856Z","shell.execute_reply":"2023-09-23T14:32:01.497251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_metric = None\nbest_epoch = None\n\ntrain_metric = []\nvalid_metric = []\n\nt_start = time.time()\nfor t in range(epochs):\n    # print(f\"Epoch {t + 1}\\n-------------------------------\")\n    \n    \n    train(train_dataloader, model, loss_fn, optimizer)\n    '''\n    metric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')  # on train without aug\n    train_metric.append(metric_tr)\n    '''\n    \n    metric, preds, ys = evaluate(valid_dataloader, model)\n    valid_metric.append(metric)\n    \n    \n    if (best_metric is None) or (metric > best_metric):\n        best_metric = metric\n        # Save the model checkpoint\n        torch.save(model.state_dict(), \"/kaggle/working/best_model_checkpoint.pth\")\n        best_epoch = t\n    \n    \n    \n    if (t%40 == 0):\n        # print(f\"Epoch {t + 1}\")\n        # print(f\"Epoch {t + 1},   train R2 = {train_metric[-1]},   valid R2 = {valid_metric[-1]}\")\n        print(f\"Epoch {t + 1},   valid R2 = {valid_metric[-1]}\")\n        \n        \n        '''\n        plt.figure()\n        plt.title(f'On test, epoch = {t}')\n        plt.plot(preds[:75], label='preds')\n        plt.plot(ys[:75], label='ys')\n        plt.legend()\n        '''\n        ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-23T14:32:01.502894Z","iopub.execute_input":"2023-09-23T14:32:01.505045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elapsed = time.time() - t_start\nprint()\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - - - - Time of evaluate\n\n'''\n\nt_start = time.time()\nmetric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')\nelapsed = time.time() - t_start\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)\n\nt_start = time.time()\nmetric, preds, ys = evaluate(valid_dataloader, model)\nelapsed = time.time() - t_start\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)\n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train vs Test prediction","metadata":{}},{"cell_type":"code","source":"model = cnn().to(device)\n\ncheckpoint_path = \"/kaggle/working/best_model_checkpoint.pth\"  \nmodel.load_state_dict(torch.load(checkpoint_path))\n\nmodel.eval()\n\nwith torch.no_grad():\n    metric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')\n    metric, preds, ys = evaluate(valid_dataloader, model)\n    metric_test, preds_test, ys_test = evaluate(test_dataloader, model)\n    \n    metric_test_Pearson, _, _ = evaluate(test_dataloader, model, metric_='Pearson')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After last epoch\nn_preds = 75\n\nplt.figure()\nplt.title(f'On TRAIN, epoch BEST = {best_epoch+1}')\nplt.plot(preds_tr[:n_preds], label='preds')\nplt.plot(ys_tr[:n_preds], label='ys')\nplt.legend()\n\nplt.figure()\nplt.title(f'On TEST, epoch BEST = {best_epoch+1}')\nplt.plot(preds_test[:n_preds], label='preds')\nplt.plot(ys_test[:n_preds], label='ys')\nplt.legend()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure for paper\n\n'''\nplt.figure(figsize = (5,1))\nplt.plot(preds_test[:n_preds], label='prediction')\nplt.plot(ys_test[:n_preds], label='true P')\nplt.xlabel('image pair number')\nplt.ylabel('P')\nplt.legend()\n\nplt.savefig('example.tiff', bbox_inches='tight')\n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# History of training","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.title('R2 score')\n# plt.plot(train_metric[:], label='train')\nplt.plot(valid_metric[:], label='valid')\n\nplt.legend()\nplt.ylim((-3, 1.1)) \n\n# print('train_metric[-1] = ', train_metric[-1])\n# print('valid_metric[-1] = ', valid_metric[-1])\n\n\nprint('     - - best_epoch: ', best_epoch)\nprint('train BEST = ', metric_tr)\nprint('test BEST R2 = ', metric_test)\nprint('test BEST Pearson = ', metric_test_Pearson)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom_ = 400\nto_ = 430\nplt.figure()\nplt.title('R2 score')\nplt.plot(train_metric[from_:to_], label='train')\nplt.plot(valid_metric[from_:to_], label='valid')\n\nplt.legend()\nplt.ylim((-3, 1.1)) \n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}