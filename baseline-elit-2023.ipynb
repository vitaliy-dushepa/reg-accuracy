{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dushepa/baseline-elit-2023?scriptVersionId=143990534\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom scipy.stats import pearsonr\nfrom sklearn.pipeline import Pipeline\n\nfrom matplotlib import pyplot as plt\nimport numpy as np \nimport pandas as pd \n\nimport cv2\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-23T17:03:05.543444Z","iopub.execute_input":"2023-09-23T17:03:05.544438Z","iopub.status.idle":"2023-09-23T17:03:05.551251Z","shell.execute_reply.started":"2023-09-23T17:03:05.544385Z","shell.execute_reply":"2023-09-23T17:03:05.549878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- realWsum,  AVIRIS_d ---  (data_preporation_for_elit_2023)\ntrain_data_path_1 = '/kaggle/input/im-registration-accur-estimation/train__wSum__AVIRIS_d__4980p.csv'\ntrain_1 = pd.read_csv(train_data_path_1)\n\ntest_data_path_1 = '/kaggle/input/im-registration-accur-estimation/test__wSum__AVIRIS_d__879p.csv'\ntest_1 = pd.read_csv(test_data_path_1)\n\n\n\nvalid_data_path_1 = '/kaggle/input/im-registration-accur-estimation/valid__wSum__AVIRIS_d__1996p.csv'\nvalid_1 = pd.read_csv(valid_data_path_1)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.553176Z","iopub.execute_input":"2023-09-23T17:03:05.553747Z","iopub.status.idle":"2023-09-23T17:03:05.674756Z","shell.execute_reply.started":"2023-09-23T17:03:05.553618Z","shell.execute_reply":"2023-09-23T17:03:05.673657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_1.copy()\ntest = test_1.copy()\n\nvalid = valid_1.copy()\n\nselect_par = 'rot'    # 'x', 'y', 'sc', 'rot', 'P'\n\n# is_P_thresh = True","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.676601Z","iopub.execute_input":"2023-09-23T17:03:05.677201Z","iopub.status.idle":"2023-09-23T17:03:05.684563Z","shell.execute_reply.started":"2023-09-23T17:03:05.677164Z","shell.execute_reply":"2023-09-23T17:03:05.683543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.686709Z","iopub.execute_input":"2023-09-23T17:03:05.686965Z","iopub.status.idle":"2023-09-23T17:03:05.697156Z","shell.execute_reply.started":"2023-09-23T17:03:05.686942Z","shell.execute_reply":"2023-09-23T17:03:05.69598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.699953Z","iopub.execute_input":"2023-09-23T17:03:05.700317Z","iopub.status.idle":"2023-09-23T17:03:05.729405Z","shell.execute_reply.started":"2023-09-23T17:03:05.700281Z","shell.execute_reply":"2023-09-23T17:03:05.728323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train[['rmse_x__ncc', 'rmse_y__ncc', 'rmse_rot__ncc', 'rmse_sc__ncc']]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.730976Z","iopub.execute_input":"2023-09-23T17:03:05.73132Z","iopub.status.idle":"2023-09-23T17:03:05.736342Z","shell.execute_reply.started":"2023-09-23T17:03:05.731287Z","shell.execute_reply":"2023-09-23T17:03:05.735174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\ntest.tail()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.737816Z","iopub.execute_input":"2023-09-23T17:03:05.738912Z","iopub.status.idle":"2023-09-23T17:03:05.765838Z","shell.execute_reply.started":"2023-09-23T17:03:05.738822Z","shell.execute_reply":"2023-09-23T17:03:05.76471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)\n# test[['P__ncc','rmse_x__ncc', 'p_Kybic','Kybic_x']] [200:300]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.767414Z","iopub.execute_input":"2023-09-23T17:03:05.767761Z","iopub.status.idle":"2023-09-23T17:03:05.775388Z","shell.execute_reply.started":"2023-09-23T17:03:05.767729Z","shell.execute_reply":"2023-09-23T17:03:05.774547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- DEBUG (Check for duplicate rows ---                                           # Attention\nduplicate_train_Rows = train[train.duplicated()]\nprint(duplicate_train_Rows)\n\nduplicate_test_Rows = test[test.duplicated()]\nprint(duplicate_test_Rows)\n\n\nduplicate_test_Rows = valid[valid.duplicated()]\nprint(duplicate_test_Rows)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.777034Z","iopub.execute_input":"2023-09-23T17:03:05.777372Z","iopub.status.idle":"2023-09-23T17:03:05.831195Z","shell.execute_reply.started":"2023-09-23T17:03:05.777341Z","shell.execute_reply":"2023-09-23T17:03:05.830255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%%\n\nif select_par != 'P':\n    print('len TRAIN before = ', len(train))\n    train.dropna(inplace = True)\n    print('len TRAIN after = ', len(train))\n    print()\n\n    print('len TEST before = ', len(test))\n    test.dropna(inplace = True)\n    print('len TEST after = ', len(test))\n\n\n\n    print('len VALID before = ', len(valid))\n    valid.dropna(inplace = True)\n    print('len VALID after = ', len(valid))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.832593Z","iopub.execute_input":"2023-09-23T17:03:05.8329Z","iopub.status.idle":"2023-09-23T17:03:05.845415Z","shell.execute_reply.started":"2023-09-23T17:03:05.832869Z","shell.execute_reply":"2023-09-23T17:03:05.844286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par != 'P':\n\n    P0 = 0.9                                                                                         # Attention\n\n    # Select rows with P >= P0\n    print('len TRAIN before = ', len(train))\n    indexces = (train['P__ncc'] >= P0)\n    train = train[indexces]\n    print('len TRAIN after = ', len(train))      # 3351\n\n\n\n    # Select rows with P >= P0\n    print('len TEST before = ', len(test))\n    indexces = (test['P__ncc'] >= P0)\n    test = test[indexces]\n    print('len TEST after = ', len(test))        # 634\n\n\n\n    print('len VALID before = ', len(valid))\n    indexces = (valid['P__ncc'] >= P0)\n    valid = valid[indexces]\n    print('len TRAIN after = ', len(valid))      # 1306\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.850341Z","iopub.execute_input":"2023-09-23T17:03:05.850619Z","iopub.status.idle":"2023-09-23T17:03:05.861677Z","shell.execute_reply.started":"2023-09-23T17:03:05.850595Z","shell.execute_reply":"2023-09-23T17:03:05.860509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par != 'P':\n    indexces_train = train.index\n    # indexces_train\n\n    indexces_test = test.index\n    # indexces_test\n\n    indexces_valid = valid.index\n    indexces_valid","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.863349Z","iopub.execute_input":"2023-09-23T17:03:05.86381Z","iopub.status.idle":"2023-09-23T17:03:05.872425Z","shell.execute_reply.started":"2023-09-23T17:03:05.863775Z","shell.execute_reply":"2023-09-23T17:03:05.871081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"code","source":"# --- All variants ---\n# features = ['ci_s'] \n#            ['subpix_x', 'subpix_y'], ---     \n#            ['scale', 'rot']\n#            ['mdx','mdy','widx','widy']\n#             ['quasi_CRLB_x', 'quasi_CRLB_y', 'quasi_CRLB_sc', 'quasi_CRLB_rot']  ---\n#             ['Kybic_x','Kybic_y','Kybic_sc','Kybic_rot']\n#             ['Kybic_x_y','Kybic_x_sc','Kybic_x_rot',\n#              'Kybic_y_sc','Kybic_y_rot','Kybic_sc_rot']\n#     Possible promising features (used in ELNANO):\n#  'dK2_dx', 'dK2_dy',\n#  'r_max','x_of_max','y_of_max','r_sd',\n#  'rr_max','x_of_rrmax','y_of_rrmax','rr_sd',\n#  'cr6', 'H'\n#\n# 'p_Kybic'                                                                   # Attention - new feature\n\nif select_par == 'P':\n    features = ['p_Kybic',\n                'ci_s',\n                'scale', 'rot',\n                'mdx','mdy','widx','widy']\n    \nelse:\n    features = ['Kybic_x','Kybic_y','Kybic_sc','Kybic_rot',\n                'ci_s',\n                'scale', 'rot',\n                'mdx','mdy','widx','widy',\n                'Kybic_x_y','Kybic_x_sc','Kybic_x_rot',\n                'Kybic_y_sc','Kybic_y_rot','Kybic_sc_rot']","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.873932Z","iopub.execute_input":"2023-09-23T17:03:05.874702Z","iopub.status.idle":"2023-09-23T17:03:05.882662Z","shell.execute_reply.started":"2023-09-23T17:03:05.874669Z","shell.execute_reply":"2023-09-23T17:03:05.881758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---- Create X and y\n\n# To scale very small features values (some ML algorithms may need it).\n# targ_norm_coef = 1000   \ntarg_norm_coef = 1000                                                                           # Attention\n\nadd_norm_for_sc = 10\n\n\n# ----------------------\nif select_par == 'x':\n    y_targ = train.rmse_x__ncc   *  targ_norm_coef\nelif select_par == 'y':\n    y_targ = train.rmse_y__ncc   *  targ_norm_coef\nelif select_par == 'sc':\n    y_targ = train.rmse_sc__ncc  *  targ_norm_coef*add_norm_for_sc\nelif select_par == 'rot':\n    y_targ = train.rmse_rot__ncc  *  targ_norm_coef\nelif select_par == 'P':                                            # Attention\n    y_targ = train.P__ncc\nelse:\n    raise ValueError('Wrong select_par value')\n# ----------------------\n    \nX = train[ features ]\n\n\n'''\n# --- DEBUG\nmask = X.isna().any(axis=1)\nprint(mask)\nrows_with_nan = X[mask]\nprint(rows_with_nan)\n'''\n\n\nif select_par == 'P':  \n    X.dropna(inplace = True)\n    indexces_train = X.index\n    y_targ = y_targ[indexces_train]\n\n\nX = X.reset_index(drop=True)\ny_targ = y_targ.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.883967Z","iopub.execute_input":"2023-09-23T17:03:05.884394Z","iopub.status.idle":"2023-09-23T17:03:05.90002Z","shell.execute_reply.started":"2023-09-23T17:03:05.884332Z","shell.execute_reply":"2023-09-23T17:03:05.898949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X.shape)\nX.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.90175Z","iopub.execute_input":"2023-09-23T17:03:05.902286Z","iopub.status.idle":"2023-09-23T17:03:05.930631Z","shell.execute_reply.started":"2023-09-23T17:03:05.902244Z","shell.execute_reply":"2023-09-23T17:03:05.929585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVR","metadata":{}},{"cell_type":"code","source":"#%% ----SVR-----\nfrom sklearn.svm import SVR\n\n# --- BEST ---\nmodel = SVR(gamma = 0.041,\n            C = 10.2,\n            epsilon = 1e-4,\n            tol = 1e-3,\n            shrinking = True,\n            cache_size = 1024,\n            verbose = False)\n\n# --- DEBUG ---\n# model = SVR(gamma = 0.041,\n#             C = 21,\n#             epsilon = 3e-5,\n#             tol = 1e-4,\n#             shrinking = True,\n#             kernel = 'sigmoid')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.932069Z","iopub.execute_input":"2023-09-23T17:03:05.932675Z","iopub.status.idle":"2023-09-23T17:03:05.941556Z","shell.execute_reply.started":"2023-09-23T17:03:05.932639Z","shell.execute_reply":"2023-09-23T17:03:05.94043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Variant 1.\n# from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n# Variant 2.\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()  \n    \nmy_pipeline = Pipeline(steps=[('scaler', scaler),\n                              ('model', model)\n                            ])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.94307Z","iopub.execute_input":"2023-09-23T17:03:05.943819Z","iopub.status.idle":"2023-09-23T17:03:05.95095Z","shell.execute_reply.started":"2023-09-23T17:03:05.943784Z","shell.execute_reply":"2023-09-23T17:03:05.950063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# nJobs = 1                           \n\n\n# my_pipeline = RandomForestRegressor(n_estimators = 132,\n#                                     n_jobs=nJobs,\n#                                     random_state=1,\n#                                     max_features = 'sqrt',\n#                                     min_samples_split = 2,\n#                                     min_samples_leaf = 5, \n#                                     max_depth = 15,\n#                                     criterion = 'mse',\n#                                     max_samples = 0.8,\n#                                     bootstrap = True )","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.952468Z","iopub.execute_input":"2023-09-23T17:03:05.953255Z","iopub.status.idle":"2023-09-23T17:03:05.961648Z","shell.execute_reply.started":"2023-09-23T17:03:05.953199Z","shell.execute_reply":"2023-09-23T17:03:05.960756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"# from xgboost import XGBRegressor\n# nJobs = 1                          \n\n# my_pipeline = XGBRegressor(learning_rate=0.01,\n#                             n_estimators=440,\n#                             n_jobs=nJobs,\n#                             random_state=1,\n#                             max_depth = 2,\n#                             min_child_weight = 1,\n#                             gamma = 0,\n#                             subsample = 0.8,\n#                             colsample_bytree = 0.8,\n#                             reg_alpha = 0.005,\n#                             reg_lambda = 1.2)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.965445Z","iopub.execute_input":"2023-09-23T17:03:05.965795Z","iopub.status.idle":"2023-09-23T17:03:05.976641Z","shell.execute_reply.started":"2023-09-23T17:03:05.965769Z","shell.execute_reply":"2023-09-23T17:03:05.975784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightGBM","metadata":{}},{"cell_type":"code","source":"# from lightgbm import LGBMRegressor\n# nJobs = 1\n\n\n# my_pipeline = LGBMRegressor(n_jobs=nJobs,\n#                             random_state=1,\n#                             importance_type = 'gain',\n#                             learning_rate = 0.01,\n#                             n_estimators = 345,\n#                             boosting_type= 'gbdt',\n#                             num_leaves= 16,\n#                             max_depth = 6,\n#                             objective = None,\n#                             min_child_weight = 1e-3,\n#                             min_child_samples= 17,\n#                             subsample = 0.6,\n#                             subsample_freq = 1,\n#                             colsample_bytree = 0.8,\n#                             reg_alpha = 23.5,\n#                             reg_lambda = 1.35,\n#                             max_bin = 400)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.977925Z","iopub.execute_input":"2023-09-23T17:03:05.978871Z","iopub.status.idle":"2023-09-23T17:03:05.988456Z","shell.execute_reply.started":"2023-09-23T17:03:05.978838Z","shell.execute_reply":"2023-09-23T17:03:05.986938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train fit","metadata":{}},{"cell_type":"code","source":"#%%\nmy_pipeline.fit(X, y_targ)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:05.989845Z","iopub.execute_input":"2023-09-23T17:03:05.990481Z","iopub.status.idle":"2023-09-23T17:03:06.528845Z","shell.execute_reply.started":"2023-09-23T17:03:05.990449Z","shell.execute_reply":"2023-09-23T17:03:06.527722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test and valid preparation","metadata":{}},{"cell_type":"code","source":"if select_par == 'x':\n    test_y_targ = test.rmse_x__ncc\n    crlb_ = test.CRLB_x         # Yetic_Nehorai estimate.\n    kybic = test.Kybic_x        # Kybic estimate.\n    \n    valid_y_targ = valid.rmse_x__ncc\nelif select_par == 'y':\n    test_y_targ = test.rmse_y__ncc\n    crlb_ = test.CRLB_y\n    kybic = test.Kybic_y \n    \n    valid_y_targ = valid.rmse_y__ncc\nelif select_par == 'sc':\n    test_y_targ = test.rmse_sc__ncc\n    crlb_ = test.CRLB_sc                                          \n    kybic = test.Kybic_sc\n    \n    valid_y_targ = valid.rmse_sc__ncc\nelif select_par == 'rot':\n    test_y_targ = test.rmse_rot__ncc\n    crlb_ = test.CRLB_rot                                          \n    kybic = test.Kybic_rot\n    \n    valid_y_targ = valid.rmse_rot__ncc\n    \nelif select_par == 'P':\n    test_y_targ = test.P__ncc\n    crlb_ = test.p_Kybic         # not make sense, just to make the code work                                     \n    kybic = test.p_Kybic\n    \n    valid_y_targ = valid.P__ncc\nelse:\n    raise ValueError('Wrong select_par value')\n\ntest_X = test[ features ]\nvalid_X = valid[ features ]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:06.530857Z","iopub.execute_input":"2023-09-23T17:03:06.531228Z","iopub.status.idle":"2023-09-23T17:03:06.542888Z","shell.execute_reply.started":"2023-09-23T17:03:06.531194Z","shell.execute_reply":"2023-09-23T17:03:06.541949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if select_par == 'P':  \n    test_X.dropna(inplace = True)\n    indexces_test = test_X.index\n    test_y_targ = test_y_targ[indexces_test]\n\n    valid_X.dropna(inplace = True)\n    indexces_valid = valid_X.index\n    valid_y_targ = valid_y_targ[indexces_valid]\n\n\ntest_X = test_X.reset_index(drop=True)\ntest_y_targ = test_y_targ.reset_index(drop=True)\n\nvalid_X = valid_X.reset_index(drop=True)\nvalid_y_targ = valid_y_targ.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:06.54436Z","iopub.execute_input":"2023-09-23T17:03:06.54477Z","iopub.status.idle":"2023-09-23T17:03:06.556431Z","shell.execute_reply.started":"2023-09-23T17:03:06.544737Z","shell.execute_reply":"2023-09-23T17:03:06.555553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance on train set","metadata":{}},{"cell_type":"code","source":"preds = my_pipeline.predict(X)\nif select_par == 'sc':\n    preds = preds / (targ_norm_coef*add_norm_for_sc)\n    y_targ = y_targ / (targ_norm_coef*add_norm_for_sc)\nelif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n    preds = preds / targ_norm_coef \n    y_targ = y_targ / targ_norm_coef\n\n\nprint()\nprint('My model    (---train performance---)')\n(pc,_) = pearsonr(preds, y_targ.values)\nprint(\"    Pearson correlation :  {0:0.3f} \".format(pc))\n\nr2 = r2_score(y_targ.values,preds)\nprint(\"    r2_score :  {0:0.3f} \".format(r2) )\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:06.557861Z","iopub.execute_input":"2023-09-23T17:03:06.558209Z","iopub.status.idle":"2023-09-23T17:03:07.086698Z","shell.execute_reply.started":"2023-09-23T17:03:06.558175Z","shell.execute_reply":"2023-09-23T17:03:07.085729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Performance on TEST set","metadata":{}},{"cell_type":"code","source":"test_preds = my_pipeline.predict(test_X)\nif select_par == 'sc':\n    test_preds = test_preds / (targ_norm_coef*add_norm_for_sc)  \nelif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n    test_preds = test_preds / targ_norm_coef\n\n\nprint()\nprint('Yetic_Nehorai')\n(pc,_) = pearsonr(crlb_.values, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values, crlb_.values)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n\n\nprint()\nprint('Kybic')\n(pc,_) = pearsonr(kybic.values, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values,kybic.values)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n\n\nprint()\nprint('My model')\n(pc,_) = pearsonr(test_preds, test_y_targ.values)\nprint(\"    Pearson correlation :  {0:0.2f} \".format(pc))\nr2 = r2_score(test_y_targ.values,test_preds)\nprint(\"    r2_score :  {0:0.2f} \".format(r2) )\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.088551Z","iopub.execute_input":"2023-09-23T17:03:07.089242Z","iopub.status.idle":"2023-09-23T17:03:07.204399Z","shell.execute_reply.started":"2023-09-23T17:03:07.089206Z","shell.execute_reply":"2023-09-23T17:03:07.203522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"code","source":"# --- Variant 1 (draw only part of points)---\nnFirst = 75\n# plt.figure(figsize = (7,3.8))\nfig = plt.figure(figsize = (5,2.5))\nax = fig.add_subplot(111)\nax.plot(test_y_targ.values[:nFirst],'r', label='true',\n          linewidth=2)\n# plt.plot(crlb_.values[:nFirst],'b', label='CRLB_')\n# plt.plot(kybic.values[:nFirst],'b', label='Kybic')\nax.plot(test_preds[:nFirst],'b--', label='prediction',\n          linewidth=3)\n# ---------------\n\n\n# --- Variant 2 ---\n# plt.plot(test_y_targ.values,'r', label='true')\n# # plt.plot(crlb_.values,'m', label='CRLB_')\n# plt.plot(kybic.values,'k', label='Kybic')\n# plt.plot(test_preds,'b', label='newML')\n# ---------------\n\nplt.grid()\nplt.legend(fontsize=10)\nplt.xlabel('Number of image pair',size =10)\nif select_par == 'x':\n    plt.ylabel('RMSE for X axis',size =10)\nelif select_par == 'y':\n    plt.ylabel('RMSE for Y axis',size =10)\nelif select_par == 'sc':\n    plt.ylabel('RMSE for scale coef',size =10)\nelif select_par == 'rot':\n    plt.ylabel('RMSE for rotation coef',size =10)\nelif select_par == 'P':\n    plt.ylabel('P',size =10)\nelse:\n    raise ValueError('Wrong select_par value')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.20608Z","iopub.execute_input":"2023-09-23T17:03:07.206441Z","iopub.status.idle":"2023-09-23T17:03:07.505255Z","shell.execute_reply.started":"2023-09-23T17:03:07.206406Z","shell.execute_reply":"2023-09-23T17:03:07.504353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% --- Plots for train predictions (DEBUG) ---\n# plt.figure()\n# plt.title('Performance on the train set')\n# plt.plot(y_targ.values,'r', label='true')\n# plt.plot(preds,'b', label='newML')\n# plt.legend(fontsize=10)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.506721Z","iopub.execute_input":"2023-09-23T17:03:07.507774Z","iopub.status.idle":"2023-09-23T17:03:07.512304Z","shell.execute_reply.started":"2023-09-23T17:03:07.507728Z","shell.execute_reply":"2023-09-23T17:03:07.511314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Neaural network**","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport matplotlib.pyplot as plt\n\n# import torchvision.transforms.v2 as T2\nimport torchvision.transforms as T\n\nimport random ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.52032Z","iopub.execute_input":"2023-09-23T17:03:07.520615Z","iopub.status.idle":"2023-09-23T17:03:07.527333Z","shell.execute_reply.started":"2023-09-23T17:03:07.52059Z","shell.execute_reply":"2023-09-23T17:03:07.5256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - - - Fixing randomness\n\nrandom.seed(13) \nnp.random.seed(13)\ntorch.manual_seed(13)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.529171Z","iopub.execute_input":"2023-09-23T17:03:07.529852Z","iopub.status.idle":"2023-09-23T17:03:07.540383Z","shell.execute_reply.started":"2023-09-23T17:03:07.52982Z","shell.execute_reply":"2023-09-23T17:03:07.539459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get cpu or gpu device for training.\ndevice = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.541708Z","iopub.execute_input":"2023-09-23T17:03:07.542041Z","iopub.status.idle":"2023-09-23T17:03:07.551258Z","shell.execute_reply.started":"2023-09-23T17:03:07.542009Z","shell.execute_reply":"2023-09-23T17:03:07.550421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import image data","metadata":{}},{"cell_type":"code","source":"import pickle\n\nfile = open('/kaggle/input/im-registration-accur-estimation/train__ci_ri_list__4980p.pkl', 'rb')\ntrain__ci_ri_list = pickle.load(file)\nfile.close()\n\nfile = open('/kaggle/input/im-registration-accur-estimation/test__ci_ri_list__879p.pkl', 'rb')\ntest__ci_ri_list = pickle.load(file)\nfile.close()\n\n\n\nfile = open('/kaggle/input/im-registration-accur-estimation/valid__ci_ri_list__1996p.pkl', 'rb')\nvalid__ci_ri_list = pickle.load(file)\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.553223Z","iopub.execute_input":"2023-09-23T17:03:07.553841Z","iopub.status.idle":"2023-09-23T17:03:07.855719Z","shell.execute_reply.started":"2023-09-23T17:03:07.553684Z","shell.execute_reply":"2023-09-23T17:03:07.854742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if \"ci_ri_list\" contain None - fixed in last version of data_praparation file\ntrain__ci_ri_list = [el for el in train__ci_ri_list if el is not None]\ntest__ci_ri_list = [el for el in test__ci_ri_list if el is not None]\n\nvalid__ci_ri_list = [el for el in valid__ci_ri_list if el is not None]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.856987Z","iopub.execute_input":"2023-09-23T17:03:07.857334Z","iopub.status.idle":"2023-09-23T17:03:07.863899Z","shell.execute_reply.started":"2023-09-23T17:03:07.857301Z","shell.execute_reply":"2023-09-23T17:03:07.862909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train__ci_ri_list))\nprint(len(test__ci_ri_list))\nprint(len(valid__ci_ri_list))\nprint()\n# print(train__ci_ri_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.865225Z","iopub.execute_input":"2023-09-23T17:03:07.865806Z","iopub.status.idle":"2023-09-23T17:03:07.876526Z","shell.execute_reply.started":"2023-09-23T17:03:07.865772Z","shell.execute_reply":"2023-09-23T17:03:07.875515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(indexces_train[:20])\nprint(indexces_test[:20])\n\nprint(indexces_valid[:20])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.878091Z","iopub.execute_input":"2023-09-23T17:03:07.878559Z","iopub.status.idle":"2023-09-23T17:03:07.889444Z","shell.execute_reply.started":"2023-09-23T17:03:07.878526Z","shell.execute_reply":"2023-09-23T17:03:07.888418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train__ci_ri_list = [train__ci_ri_list[i] for i in indexces_train]\ntest__ci_ri_list = [test__ci_ri_list[i] for i in indexces_test]\n\nvalid__ci_ri_list = [valid__ci_ri_list[i] for i in indexces_valid]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.890604Z","iopub.execute_input":"2023-09-23T17:03:07.891118Z","iopub.status.idle":"2023-09-23T17:03:07.903421Z","shell.execute_reply.started":"2023-09-23T17:03:07.891085Z","shell.execute_reply":"2023-09-23T17:03:07.90245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check that length coinside\nprint(len(train__ci_ri_list))\nprint(len(test__ci_ri_list))\nprint(len(valid__ci_ri_list))\nprint()\n\nprint(len(X))\nprint(len(test_X))\nprint(len(valid_X))\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.90524Z","iopub.execute_input":"2023-09-23T17:03:07.907717Z","iopub.status.idle":"2023-09-23T17:03:07.916843Z","shell.execute_reply.started":"2023-09-23T17:03:07.907683Z","shell.execute_reply":"2023-09-23T17:03:07.915993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train__ci_ri_list[0]","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.918688Z","iopub.execute_input":"2023-09-23T17:03:07.918931Z","iopub.status.idle":"2023-09-23T17:03:07.930532Z","shell.execute_reply.started":"2023-09-23T17:03:07.918908Z","shell.execute_reply":"2023-09-23T17:03:07.929551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"\naug_train = T.Compose([ToTensor(),\n                      T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                     interpolation=T.InterpolationMode.BILINEAR)]\n                  )\nno_aug_test = ToTensor()\n'''\nprint()\n'''","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.932093Z","iopub.execute_input":"2023-09-23T17:03:07.933091Z","iopub.status.idle":"2023-09-23T17:03:07.943639Z","shell.execute_reply.started":"2023-09-23T17:03:07.933032Z","shell.execute_reply":"2023-09-23T17:03:07.942747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_size = 60   # 60, 128  , 120                                       # Attention\n\nclass Dataset(torch.utils.data.Dataset):\n    \"\"\"\n    dataset = Dataset(X, y, ci_ri_list)\n    ci_ri_list - list of Hx2H images\n    len(X)==len(ci_ri_list)\n    \n    \n    img, feat, y = dataset[i]\n      img :     image (2xHxH)\n      features : array og features\n      y :    regression target (RMSE_x, RMSE_y, RMSE_scale, RMSE_rot, P, ...)\n          (for 'test data' you can give random y array)\n    \"\"\"\n    \n    def __init__(self, X, y, ci_ri_list, mode=None):\n        self.X = X\n        self.y = y\n        self.ci_ri_list = ci_ri_list\n        self.mode = mode                    # 'train' or None\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, i):\n        ci_ri = self.ci_ri_list[i]\n        n,m = ci_ri.shape\n        # print('n,m = ', n,m),  # m=2*n\n        \n        ci = ci_ri[:, :n]\n        ri_fragm = ci_ri[:, n:]\n        \n        \n        dim = (im_size, im_size)\n        ci_ = cv2.resize(ci, dim, interpolation = cv2.INTER_CUBIC)\n        ri_fragm_ = cv2.resize(ri_fragm, dim, interpolation = cv2.INTER_CUBIC)\n        \n        \n        img = np.zeros( (im_size,im_size,2) )   # H,W, C\n        img[:,:,0] = ci_\n        img[:,:,1] = ri_fragm_\n        \n        img = img/255.0\n        \n        if self.mode == 'train':   # transformation\n            img = aug_train(img)   # C,H,W\n        else:\n            img = no_aug_test(img)\n        \n        # features = self.X.iloc[i,:]\n        features = self.X.iloc[i,:].values\n        \n        y = self.y.iloc[i]\n        # y = np.float64(self.y.iloc[i])\n        \n        return img.float(), torch.tensor(features).float(), torch.tensor(y).float() ","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.944794Z","iopub.execute_input":"2023-09-23T17:03:07.945183Z","iopub.status.idle":"2023-09-23T17:03:07.957437Z","shell.execute_reply.started":"2023-09-23T17:03:07.945148Z","shell.execute_reply":"2023-09-23T17:03:07.956453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------------\nif select_par == 'x':\n    y_targ = y_targ   *  targ_norm_coef\nelif select_par == 'y':\n    y_targ = y_targ   *  targ_norm_coef\nelif select_par == 'sc':\n    y_targ = y_targ  *  targ_norm_coef*add_norm_for_sc\nelif select_par == 'rot':\n    y_targ = y_targ  *  targ_norm_coef\nelif select_par == 'P':\n    y_targ = y_targ\nelse:\n    raise ValueError('Wrong select_par value')\n# ----------------------\n\n\nprint('y_targ = ', y_targ[:10])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.958866Z","iopub.execute_input":"2023-09-23T17:03:07.959599Z","iopub.status.idle":"2023-09-23T17:03:07.974717Z","shell.execute_reply.started":"2023-09-23T17:03:07.959567Z","shell.execute_reply":"2023-09-23T17:03:07.973773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(X, y_targ, train__ci_ri_list, mode='train')           # Perform augmentations on samples\n# train_dataset = Dataset(X, y_targ, train__ci_ri_list, mode=None)           # Perform augmentations on batches (modified model)\n\ntest_dataset = Dataset(test_X, test_y_targ, test__ci_ri_list, mode=None)\n\nvalid_dataset = Dataset(valid_X, valid_y_targ, valid__ci_ri_list, mode=None)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.97783Z","iopub.execute_input":"2023-09-23T17:03:07.978099Z","iopub.status.idle":"2023-09-23T17:03:07.988458Z","shell.execute_reply.started":"2023-09-23T17:03:07.978075Z","shell.execute_reply":"2023-09-23T17:03:07.987428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- Examine dataset class\nind = 5\n'''\nimg, feat, y = train_dataset[ind]\n\nprint('img = ', img)\nprint('feat = ', feat)\nprint('y = ', y)\n'''\nimg, feat, y = test_dataset[ind]\n\nprint('img = ', img)\nprint('feat = ', feat)\nprint('y = ', y)\n\nplt.figure()\nplt.imshow(img[0,:,:])\nplt.figure()\nplt.imshow(img[1,:,:])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:07.990008Z","iopub.execute_input":"2023-09-23T17:03:07.990377Z","iopub.status.idle":"2023-09-23T17:03:08.480417Z","shell.execute_reply.started":"2023-09-23T17:03:07.990345Z","shell.execute_reply":"2023-09-23T17:03:08.479458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"# the code from the example is partially used\n# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n\nbatch_size = 64            # 64  , 128,  256   ,  512  , 1024                                                         # Attention\nvalid_bs = 2*4096\n\n# Create data loaders.\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n                              drop_last=True, shuffle=True,\n                              num_workers=2)                                   # Attention\n\n\ntest_dataloader = DataLoader(test_dataset, batch_size=valid_bs,\n                             drop_last=False, shuffle=False,\n                             num_workers=2)\n\nvalid_dataloader = DataLoader(valid_dataset, batch_size=valid_bs,\n                             drop_last=False, shuffle=False,\n                             num_workers=2)\n\n# --- DEBUG\nfor img, feat, y in train_dataloader:\n    print(f\"Shape of img [N, C, H, W]: {img.shape}\")\n    print(f\"Shape of feat [N, C, H, W]: {feat.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.483874Z","iopub.execute_input":"2023-09-23T17:03:08.485766Z","iopub.status.idle":"2023-09-23T17:03:08.902805Z","shell.execute_reply.started":"2023-09-23T17:03:08.485736Z","shell.execute_reply":"2023-09-23T17:03:08.90127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_no_aug = Dataset(X, y_targ, train__ci_ri_list, mode=None)  \ntrain_dataloader_no_aug = DataLoader(train_dataset_no_aug, batch_size=valid_bs,\n                              drop_last=False, shuffle=False,\n                              num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.904962Z","iopub.execute_input":"2023-09-23T17:03:08.905339Z","iopub.status.idle":"2023-09-23T17:03:08.931991Z","shell.execute_reply.started":"2023-09-23T17:03:08.905301Z","shell.execute_reply":"2023-09-23T17:03:08.926045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"mode = 'cnn_with_features'   #  'cnn_with_features', 'cnn_10' ,     'cnn_32' don't used in paper \nattention_mode = True    # only for 'cnn_with_features', 'cnn_10'\nnormFeat_mode = True     # only for 'cnn_with_features' (norm before concat conv[or attention] and hand-made features), \n                         #          'cnn_10'  (norm before concat attention in and out,        work when attention_mode = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.933619Z","iopub.execute_input":"2023-09-23T17:03:08.933971Z","iopub.status.idle":"2023-09-23T17:03:08.940109Z","shell.execute_reply.started":"2023-09-23T17:03:08.933938Z","shell.execute_reply":"2023-09-23T17:03:08.938999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN_3","metadata":{}},{"cell_type":"code","source":"\nif mode == 'cnn_10': \n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            self.conv_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n                \n\n                nn.Conv2d(in_channels=4, out_channels=6, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n                \n\n                nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n\n                \n                nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(10, affine=True),\n                nn.ReLU()\n            )\n\n            \n            n_conv_feat = 10*2*2     # 10*2*2, 810 , 20*2*2                                # Attention\n            # self.norm_on_batch = nn.BatchNorm1d(num_features=n_conv_feat)\n            self.norm_on_batch = nn.BatchNorm1d(num_features=int(n_conv_feat/2))    # if concat with attention case \n            \n            self.norm_on_channel = nn.LayerNorm(normalized_shape=10)  # only on channels \n            \n            self.dense_stack = nn.Sequential(\n                nn.Linear(n_conv_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n            \n            num_heads = 5\n            embed_dim = 10\n            self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n            \n\n        def forward(self, x):\n\n            '''\n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                x = self.transf(x)\n            '''\n            \n            \n            conv_feat = self.conv_stack(x)      # N C H W   (N-batch,  C- channels, H-height, W-width)\n            \n            \n            \n            # - - - - - - With attention\n            if attention_mode:\n                # print('conv_feat.shape = ', conv_feat.shape)\n                conv_feat = conv_feat.flatten(2, 3)     # N C S   (S-sequence)\n                \n                conv_feat_ = conv_feat.permute(2,0,1)    # S N C\n                # --- 1st self-attention \n                attn_output, attn_output_weights = self.multihead_attn(query=conv_feat_, \n                                                                       key=conv_feat_, \n                                                                       value=conv_feat_)     # attn_output    # S N C\n                '''\n                attn_output, attn_output_weights = self.multihead_attn(query=attn_output, \n                                                                       key=attn_output, \n                                                                       value=attn_output)     # attn_output    # S N C\n                '''\n                \n                attn_output_ = attn_output.permute(1,2,0)    # N C S\n                \n                \n                # - - - - - - Norm before concat (in and out of attention)\n                if normFeat_mode:\n                    # --  Norm on batch\n                    '''\n                    conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n                    conv_feat = self.norm_on_batch(conv_feat)\n                    attn_output_ = attn_output_.flatten(1, -1)     # N F    (F-features)\n                    attn_output_ = self.norm_on_batch(attn_output_)\n                    '''\n                    # --  Norm on channel (only attention out)\n                    attn_output_ = attn_output_.permute(0,2,1)    # N S C\n                    attn_output_ = self.norm_on_channel(attn_output_)   # Norm on C (last dimension) only\n                    attn_output_ = attn_output_.permute(0,2,1)    # N C S\n                # - - - - - - - -- - - - - - - -- - - - - -- - \n                \n                \n                \n                # conv_feat = attn_output_                  # only attn_output\n                # conv_feat = conv_feat + attn_output_        # add attn_output with input      # N C S\n                conv_feat = torch.cat((conv_feat, attn_output_), dim=1)         #       # N 2*C S\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            \n            conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n            \n            \n            logits = self.dense_stack(conv_feat)\n            return logits","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.942104Z","iopub.execute_input":"2023-09-23T17:03:08.942539Z","iopub.status.idle":"2023-09-23T17:03:08.963854Z","shell.execute_reply.started":"2023-09-23T17:03:08.942438Z","shell.execute_reply":"2023-09-23T17:03:08.962847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if mode == 'cnn_32': \n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            n_conv_feat = 2592     # 32*2*2,  2592\n            self.cnn_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=8, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n                \n\n                nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(16, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(16, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n                \n\n                nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(24, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=24, out_channels=24, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(24, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n\n                \n                nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(32, affine=True),\n                nn.ReLU(),\n\n                \n                nn.Flatten(),\n                nn.Linear(n_conv_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n\n        def forward(self, x):\n\n            '''\n            \n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                x = self.transf(x)\n            '''\n            \n            \n            \n            logits = self.cnn_stack(x)\n            return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.966534Z","iopub.execute_input":"2023-09-23T17:03:08.967071Z","iopub.status.idle":"2023-09-23T17:03:08.981714Z","shell.execute_reply.started":"2023-09-23T17:03:08.967039Z","shell.execute_reply":"2023-09-23T17:03:08.980747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combine cnn+features","metadata":{}},{"cell_type":"code","source":"# train_metric[-1] =  0.3254600726401089\n# test_metric[-1] =  0.25901960194265294   'rot'\n\nn_feat = len(features)   # 17, 8\n\nif mode == 'cnn_with_features':  \n    print(\"       'cnn_with_features' is used\")\n\n    class cnn(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.transf = T.RandomAffine(degrees=(-30, 30), translate=(0.2, 0.2), scale=(0.9, 1.1), \n                                         interpolation=T.InterpolationMode.BILINEAR)\n\n            self.conv_stack = nn.Sequential(\n                nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3),   # 58x58\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3),   # 56x56\n                nn.BatchNorm2d(4, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 28x28\n\n                nn.Conv2d(in_channels=4, out_channels=6, kernel_size=3),   # 26x26\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3),   # 24x24\n                nn.BatchNorm2d(6, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 12x12\n\n                nn.Conv2d(in_channels=6, out_channels=8, kernel_size=3),   # 10x10\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3),   # 8x8\n                nn.BatchNorm2d(8, affine=True),\n                nn.ReLU(),\n                nn.MaxPool2d(2),                                           # 4x4\n                \n                nn.Conv2d(in_channels=8, out_channels=10, kernel_size=3),   # 2x2\n                nn.BatchNorm2d(10, affine=True),\n                nn.ReLU()\n            )\n            \n            # self.flat = nn.Flatten()\n            \n            n_conv_feat = 10*2*2     # 10*2*2,  20*2*2\n            self.norm_on_batch = nn.BatchNorm1d(num_features=n_conv_feat)\n            # self.norm_on_batch = nn.BatchNorm1d(num_features=int(n_conv_feat/2))    # if concat with attention case\n            \n            self.norm_on_channel = nn.LayerNorm(normalized_shape=10)  # only on channels \n            \n            \n            \n            self.feat_norm = nn.BatchNorm1d(n_feat)\n            \n            self.dense_stack = nn.Sequential(\n                nn.Linear(n_conv_feat + n_feat, 16),\n                nn.ReLU(),\n                nn.Linear(16, 1)\n            )\n            \n            num_heads = 5\n            embed_dim = 10\n            self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n            \n\n\n        def forward(self, img, feat):\n            '''\n            # - - IF augmentation in batch                                   # Attention\n            if self.training:\n                img = self.transf(img)\n                # plt.figure()\n                # plt.imshow(x[0,0,:,:].detach().cpu().numpy())\n            '''\n\n            conv_feat = self.conv_stack(img)    # N C H W   (N-batch,  C- channels, H-height, W-width)\n            \n            # - - - - - - With attention\n            if attention_mode:\n                conv_feat = conv_feat.flatten(2, 3)     # N C S   (S-sequence)\n                conv_feat_ = conv_feat.permute(2,0,1)    # S N C\n                # --- 1st self-attention \n                attn_output, attn_output_weights = self.multihead_attn(query=conv_feat_, \n                                                                       key=conv_feat_, \n                                                                       value=conv_feat_)     # attn_output    # S N C\n                '''\n                attn_output, attn_output_weights = self.multihead_attn(query=attn_output, \n                                                                       key=attn_output, \n                                                                       value=attn_output)     # attn_output    # S N C\n                '''\n                attn_output_ = attn_output.permute(1,2,0)    # N C S\n\n                # - - - - - - Norm out of attention\n                if normFeat_mode:\n                    # - - --  Norm on batch\n                    '''\n                    # conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n                    # conv_feat = self.norm_on_batch(conv_feat)\n                    attn_output_ = attn_output_.flatten(1, -1)     # N F    (F-features)\n                    attn_output_ = self.norm_on_batch(attn_output_)\n                    '''\n                    # --  Norm on channel (only attention out)\n                    attn_output_ = attn_output_.permute(0,2,1)    # N S C\n                    attn_output_ = self.norm_on_channel(attn_output_)   # Norm on C (last dimension) only\n                    attn_output_ = attn_output_.permute(0,2,1)    # N C S\n                    \n                # - - - - - - - -- - - - - - - -- - - - - -- - \n                \n                \n                \n                conv_feat = attn_output_                  # only attn_output\n                # conv_feat = conv_feat + attn_output_        # add attn_output with input      # N C S\n                # conv_feat = torch.cat((conv_feat, attn_output_), dim=1)         #       # N 2*C S\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            \n            conv_feat = conv_feat.flatten(1, -1)     # N F    (F-features)\n            \n            \n            # - - - - - - With feat norm\n            if normFeat_mode:\n                if not attention_mode:\n                    conv_feat = self.norm_on_batch(conv_feat)        # norm by batch\n\n                feat = self.feat_norm(feat)         # N F    (F-features)\n            # - - - - - - - -- - - - - - - -- - - - - -- - \n            \n            x = torch.cat((conv_feat,feat), axis=1)    \n\n            logits = self.dense_stack(x)\n            return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:08.983367Z","iopub.execute_input":"2023-09-23T17:03:08.983814Z","iopub.status.idle":"2023-09-23T17:03:09.005791Z","shell.execute_reply.started":"2023-09-23T17:03:08.983752Z","shell.execute_reply":"2023-09-23T17:03:09.004907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = cnn().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.00709Z","iopub.execute_input":"2023-09-23T17:03:09.007438Z","iopub.status.idle":"2023-09-23T17:03:09.028296Z","shell.execute_reply.started":"2023-09-23T17:03:09.007405Z","shell.execute_reply":"2023-09-23T17:03:09.027306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchinfo import summary\n\nif (mode == 'cnn_10') or (mode == 'cnn_32'): \n    print(\n        summary(model, input_size=(batch_size, 2, im_size, im_size))\n    )\nelif mode == 'cnn_with_features': \n    print(\n        summary(model, input_size=[(batch_size, 2, im_size, im_size), (batch_size,n_feat)] \n                )\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.0298Z","iopub.execute_input":"2023-09-23T17:03:09.030192Z","iopub.status.idle":"2023-09-23T17:03:09.053467Z","shell.execute_reply.started":"2023-09-23T17:03:09.030161Z","shell.execute_reply":"2023-09-23T17:03:09.052564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.MSELoss()\n# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)         # Attention\n# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n\nepochs = 250   # 500,  250  , 100                                     # Attention\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=7e-4, steps_per_epoch=len(train_dataloader), epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.054624Z","iopub.execute_input":"2023-09-23T17:03:09.055486Z","iopub.status.idle":"2023-09-23T17:03:09.062103Z","shell.execute_reply.started":"2023-09-23T17:03:09.055454Z","shell.execute_reply":"2023-09-23T17:03:09.061207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.to(torch.double)\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.063329Z","iopub.execute_input":"2023-09-23T17:03:09.063979Z","iopub.status.idle":"2023-09-23T17:03:09.073903Z","shell.execute_reply.started":"2023-09-23T17:03:09.063945Z","shell.execute_reply":"2023-09-23T17:03:09.072902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# the code from the example is partially used\n# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (img, feat, y) in enumerate(dataloader):\n        img, feat, y = img.to(device), feat.to(device), y.to(device)\n\n        # Compute prediction error\n        if mode == 'cnn_with_features':\n            pred = model(img, feat)\n        elif (mode == 'cnn_10') or (mode == 'cnn_32'):\n            pred = model(img)\n        pred = torch.squeeze(pred)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.075215Z","iopub.execute_input":"2023-09-23T17:03:09.075703Z","iopub.status.idle":"2023-09-23T17:03:09.084624Z","shell.execute_reply.started":"2023-09-23T17:03:09.07567Z","shell.execute_reply":"2023-09-23T17:03:09.083562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchmetrics.functional import r2_score as r2_torch     # strangely works for small values\n\ndef evaluate(dataloader, model, mode_='test', \n             metric_='R2'):                           # 'R2', 'Pearson'\n    model.eval()\n    preds = torch.empty((0,), dtype=torch.float64).to(device)\n    ys = torch.empty((0,), dtype=torch.float64).to(device)\n    \n    with torch.no_grad():\n        for img, feat, y in dataloader:\n            img, feat, y = img.to(device), feat.to(device), y.to(device)\n            \n            if mode == 'cnn_with_features':\n                pred = model(img, feat)\n            elif (mode == 'cnn_10') or (mode == 'cnn_32'):\n                pred = model(img)\n                \n            pred = torch.squeeze(pred)\n            preds = torch.cat((preds, pred))\n            ys = torch.cat((ys, y))\n    \n    preds = preds.detach().cpu().numpy()\n    ys = ys.detach().cpu().numpy()\n    \n    # - - - - - - - - - - -\n    if select_par == 'sc':\n        preds = preds / (targ_norm_coef*add_norm_for_sc)\n        if mode_ == 'train':     # for train, target multiplied by constant (small value issue)\n            ys = ys / (targ_norm_coef*add_norm_for_sc)\n    elif (select_par == 'x') or (select_par == 'y') or (select_par == 'rot'):\n        preds = preds / targ_norm_coef\n        if mode_ == 'train':\n            ys = ys / targ_norm_coef\n    # - - - - - - - - - - -\n    \n    if metric_ == 'R2':\n        metric = r2_score(ys,preds)      # in sklean function: r2_score(true, pred)\n    elif metric_ == 'Pearson':\n        metric,_ = pearsonr(preds,ys)      # (preds,ys) the order doesn't matter\n\n    return metric, preds, ys\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.085999Z","iopub.execute_input":"2023-09-23T17:03:09.086597Z","iopub.status.idle":"2023-09-23T17:03:09.099119Z","shell.execute_reply.started":"2023-09-23T17:03:09.086564Z","shell.execute_reply":"2023-09-23T17:03:09.098137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(train_dataloader))[0].shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T17:03:09.100476Z","iopub.execute_input":"2023-09-23T17:03:09.101101Z","iopub.status.idle":"2023-09-23T17:03:09.529735Z","shell.execute_reply.started":"2023-09-23T17:03:09.101067Z","shell.execute_reply":"2023-09-23T17:03:09.528558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_metric = None\nbest_epoch = None\n\ntrain_metric = []\nvalid_metric = []\n\nt_start = time.time()\nfor t in range(epochs):\n    # print(f\"Epoch {t + 1}\\n-------------------------------\")\n    \n    \n    train(train_dataloader, model, loss_fn, optimizer)\n    '''\n    metric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')  # on train without aug\n    train_metric.append(metric_tr)\n    '''\n    \n    metric, preds, ys = evaluate(valid_dataloader, model)\n    valid_metric.append(metric)\n    \n    \n    if (best_metric is None) or (metric > best_metric):\n        best_metric = metric\n        # Save the model checkpoint\n        torch.save(model.state_dict(), \"/kaggle/working/best_model_checkpoint.pth\")\n        best_epoch = t\n    \n    \n    \n    if (t%40 == 0):\n        # print(f\"Epoch {t + 1}\")\n        # print(f\"Epoch {t + 1},   train R2 = {train_metric[-1]},   valid R2 = {valid_metric[-1]}\")\n        print(f\"Epoch {t + 1},   valid R2 = {valid_metric[-1]}\")\n        \n        \n        '''\n        plt.figure()\n        plt.title(f'On test, epoch = {t}')\n        plt.plot(preds[:75], label='preds')\n        plt.plot(ys[:75], label='ys')\n        plt.legend()\n        '''\n        ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-23T17:03:09.531911Z","iopub.execute_input":"2023-09-23T17:03:09.532308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"elapsed = time.time() - t_start\nprint()\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# - - - - Time of evaluate\n\n'''\n\nt_start = time.time()\nmetric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')\nelapsed = time.time() - t_start\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)\n\nt_start = time.time()\nmetric, preds, ys = evaluate(valid_dataloader, model)\nelapsed = time.time() - t_start\nprint('Time, s = ', elapsed,  '    Time, hours = ', elapsed / 3600)\n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train vs Test prediction","metadata":{}},{"cell_type":"code","source":"model = cnn().to(device)\n\ncheckpoint_path = \"/kaggle/working/best_model_checkpoint.pth\"  \nmodel.load_state_dict(torch.load(checkpoint_path))\n\nmodel.eval()\n\nwith torch.no_grad():\n    metric_tr, preds_tr, ys_tr = evaluate(train_dataloader_no_aug, model, mode_='train')\n    metric, preds, ys = evaluate(valid_dataloader, model)\n    metric_test, preds_test, ys_test = evaluate(test_dataloader, model)\n    \n    metric_test_Pearson, _, _ = evaluate(test_dataloader, model, metric_='Pearson')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After last epoch\nn_preds = 75\n\nplt.figure()\nplt.title(f'On TRAIN, epoch BEST = {best_epoch+1}')\nplt.plot(preds_tr[:n_preds], label='preds')\nplt.plot(ys_tr[:n_preds], label='ys')\nplt.legend()\n\nplt.figure()\nplt.title(f'On TEST, epoch BEST = {best_epoch+1}')\nplt.plot(preds_test[:n_preds], label='preds')\nplt.plot(ys_test[:n_preds], label='ys')\nplt.legend()\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create figure for paper\n\n'''\nplt.figure(figsize = (5,1))\nplt.plot(preds_test[:n_preds], label='prediction')\nplt.plot(ys_test[:n_preds], label='true P')\nplt.xlabel('image pair number')\nplt.ylabel('P')\nplt.legend()\n\nplt.savefig('example.tiff', bbox_inches='tight')\n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# History of training","metadata":{}},{"cell_type":"code","source":"plt.figure()\nplt.title('R2 score')\n# plt.plot(train_metric[:], label='train')\nplt.plot(valid_metric[:], label='valid')\n\nplt.legend()\nplt.ylim((-3, 1.1)) \n\n# print('train_metric[-1] = ', train_metric[-1])\n# print('valid_metric[-1] = ', valid_metric[-1])\n\n\nprint('     - - best_epoch: ', best_epoch)\nprint('train BEST = ', metric_tr)\nprint('test BEST R2 = ', metric_test)\nprint('test BEST Pearson = ', metric_test_Pearson)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfrom_ = 400\nto_ = 430\nplt.figure()\nplt.title('R2 score')\nplt.plot(train_metric[from_:to_], label='train')\nplt.plot(valid_metric[from_:to_], label='valid')\n\nplt.legend()\nplt.ylim((-3, 1.1)) \n'''\nprint()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}